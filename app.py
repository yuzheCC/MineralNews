import streamlit as st
import requests
import json
from datetime import datetime, timedelta
import pandas as pd
from openai import OpenAI
import re
from urllib.parse import urlparse
from serpapi import GoogleSearch
from bs4 import BeautifulSoup
import time

# ç®€å•çš„é“¾æ¥éªŒè¯å‡½æ•°
def validate_url(url):
    """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
    if not url or url.strip() == "":
        return False, "ç©ºé“¾æ¥"
    
    # æ£€æŸ¥URLæ ¼å¼
    try:
        parsed = urlparse(url)
        if not parsed.scheme or not parsed.netloc:
            return False, "æ— æ•ˆçš„URLæ ¼å¼"
    except:
        return False, "URLè§£æå¤±è´¥"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
    invalid_patterns = [
        r'example\.com',
        r'placeholder\.com',
        r'test\.com',
        r'sample\.com',
        r'news\.cnstock\.com.*202508',  # æ‚¨æåˆ°çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
        r'www\.cs\.com\.cn.*202508'     # æ‚¨æåˆ°çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
    ]
    
    for pattern in invalid_patterns:
        if re.search(pattern, url, re.IGNORECASE):
            return False, "æ— æ•ˆé“¾æ¥æ¨¡å¼"
    
    return True, "é“¾æ¥æ ¼å¼æœ‰æ•ˆ"

def process_and_validate_result(result):
    """åå¤„ç†éªŒè¯APIè¿”å›ç»“æœä¸­çš„é“¾æ¥"""
    if not result or result.startswith("âŒ"):
        return result
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„è™šå‡é“¾æ¥æ¨¡å¼
    fake_patterns = [
        r'content_\d{6,}\.html?',  # content_123456.html
        r'/\d{10,}\.html?',        # /1234567890.html
        r'0{8,}',                  # è¿ç»­8ä¸ªæˆ–æ›´å¤šé›¶
        r'content_\d+\.htm',       # content_æ•°å­—.htm
        r'/202\d{1}/\d{8,}\.html', # /2025/12345678.html
    ]
    
    contains_fake_link = False
    for pattern in fake_patterns:
        if re.search(pattern, result):
            contains_fake_link = True
            break
    
    if contains_fake_link:
        # å¦‚æœæ£€æµ‹åˆ°è™šå‡é“¾æ¥ï¼Œæ›¿æ¢ä¸ºè­¦å‘Šä¿¡æ¯
        warning_msg = """
âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„è™šå‡é“¾æ¥ï¼Œç³»ç»Ÿæ— æ³•æä¾›çœŸå®å¯è®¿é—®çš„æ–°é—»é“¾æ¥ã€‚

å¯èƒ½çš„åŸå› ï¼š
1. è”ç½‘æœç´¢åŠŸèƒ½æœªæ­£å¸¸å·¥ä½œ
2. æœç´¢ç»“æœä¸­æ²¡æœ‰åŒ…å«æœ‰æ•ˆçš„æ–°é—»é“¾æ¥
3. å½“å‰æ—¶é—´èŒƒå›´å†…ç¼ºå°‘ç›¸å…³æ–°é—»

å»ºè®®ï¼š
- å°è¯•è°ƒæ•´å…³é”®è¯æˆ–æ—¶é—´èŒƒå›´
- ç¨åé‡è¯•æœç´¢
- è”ç³»æŠ€æœ¯æ”¯æŒæ£€æŸ¥è”ç½‘æœç´¢åŠŸèƒ½
        """
        
        if st.session_state.language == "en":
            warning_msg = """
âš ï¸ Detected potentially fake links. The system cannot provide real accessible news links.

Possible reasons:
1. Web search functionality not working properly
2. Search results contain no valid news links
3. Lack of relevant news in current time range

Suggestions:
- Try adjusting keywords or time range
- Retry search later
- Contact technical support to check web search functionality
            """
        
        return warning_msg
    
    return result

# å›½é™…åŒ–é…ç½®
LANGUAGES = {
    "en": {
        "title": "ğŸ” Critical Minerals News Analysis System",
        "tab1_title": "ğŸ“° News Filtering Analysis",
        "tab2_title": "ğŸ’¬ Custom Prompt",
        "keywords_title": "ğŸ”‘ Keyword Selection",
        "companies_title": "ğŸ¢ Company Selection", 
        "time_title": "â° Time Selection",
        "start_analysis": "ğŸš€ Start Analysis",
        "custom_prompt": "ğŸ’¬ Custom Prompt",
        "example_prompts": "ğŸ“š Example Prompts",
        "model_selection": "Model Selection",
        "analyze_button": "ğŸ” Start Analysis",
        "time_options": {
            "2_weeks": "Last 2 Weeks",
            "2_days": "Last 2 Days", 
            "custom": "Custom Time Range"
        },
        "start_date": "Start Date",
        "end_date": "End Date",
        "time_range_info": "ğŸ“… Time Range",
        "selected_companies": "Selected Companies",
        "news_analysis": "News Analysis",
        "generated_prompt": "Generated Prompt",
        "analysis_results": "Analysis Results",
        "last_results": "Last Analysis Results",
        "view_last_results": "View Last Results",
        "custom_input": "Custom Input",
        "edit_selected_prompt": "Edit Selected Prompt",
        "input_prompt": "Input Your Prompt",
        "prompt_placeholder": "Enter your prompt here...",
        "help_text": "Select DeepSeek model version",
        "error_no_keywords": "Please select at least one keyword!",
        "error_no_companies": "Please select at least one company!",
        "error_no_prompt": "Please enter prompt content!",
        "analyzing": "Analyzing with API...",
        "step1_analyzing": "ğŸ” Step 1: Analyzing custom prompt...",
        "step2_converting": "ğŸ”„ Step 2: Converting output language according to UI language setting...",
        "language_conversion_prompt": "ğŸ”„ Language Conversion Prompt",
        "api_key_expired": "âŒ API key expired, please update your DeepSeek API key",
        "api_quota_exceeded": "âŒ API quota exceeded, please check your account balance",
        "api_error": "âŒ API call error",
        "news_prompt_template": "Please help me find the LATEST and MOST RECENT news about the following keywords and companies in {time_range}:\n\nKeywords: {keywords}\nCompanies: {companies}\n\nCRITICAL TIME REQUIREMENTS:\n1. The time range '{time_range}' refers to the CURRENT DATE and time - NOT historical dates from previous years\n2. If the prompt mentions 'last 24 hours', 'last 2 weeks', etc., calculate this from TODAY'S DATE, not from 2024 or any other past year\n3. ONLY provide news that was published or occurred within the specified time range from TODAY\n4. If no recent news exists in the specified time range, clearly state 'No recent news found in {time_range} (calculated from current date)' instead of providing old information\n5. NEVER reference dates from 2024, 2023, or any previous years unless they are specifically relevant to current developments\n\nPlease provide:\n1. Title, source, and publication time for each news item\n2. Relevance score (0-1, 1 being most relevant) for each news item with selected keywords and companies\n3. Source Link: URL link to the original news article (must be real and accessible)\n4. News summary\n5. News complete content\n6. Sorted by relevance and recency\n\nPlease answer in English with clear formatting and ensure ALL news is from the specified time period calculated from TODAY'S DATE."
    },
    "zh": {
        "title": "ğŸ” å…³é”®çŸ¿äº§æ–°é—»åˆ†æç³»ç»Ÿ",
        "tab1_title": "ğŸ“° æ–°é—»ç­›é€‰åˆ†æ",
        "tab2_title": "ğŸ’¬ è‡ªå®šä¹‰Prompt",
        "keywords_title": "ğŸ”‘ å…³é”®è¯é€‰æ‹©",
        "companies_title": "ğŸ¢ å…¬å¸é€‰æ‹©",
        "time_title": "â° æ—¶é—´é€‰æ‹©", 
        "start_analysis": "ğŸš€ å¼€å§‹åˆ†æ",
        "custom_prompt": "ğŸ’¬ è‡ªå®šä¹‰Prompt",
        "example_prompts": "ğŸ“š ç¤ºä¾‹Prompt",
        "model_selection": "æ¨¡å‹é€‰æ‹©",
        "analyze_button": "ğŸ” å¼€å§‹åˆ†æ",
        "time_options": {
            "2_weeks": "æœ€è¿‘2å‘¨",
            "2_days": "æœ€è¿‘2å¤©",
            "custom": "è‡ªå®šä¹‰æ—¶é—´åŒºé—´"
        },
        "start_date": "å¼€å§‹æ—¥æœŸ",
        "end_date": "ç»“æŸæ—¥æœŸ",
        "time_range_info": "ğŸ“… æ—¶é—´èŒƒå›´",
        "selected_companies": "å·²é€‰å…¬å¸",
        "news_analysis": "æ–°é—»åˆ†æ",
        "generated_prompt": "ç”Ÿæˆçš„Prompt",
        "analysis_results": "åˆ†æç»“æœ",
        "last_results": "ä¸Šæ¬¡åˆ†æç»“æœ",
        "view_last_results": "æŸ¥çœ‹ä¸Šæ¬¡ç»“æœ",
        "custom_input": "è‡ªå®šä¹‰è¾“å…¥",
        "edit_selected_prompt": "ç¼–è¾‘é€‰ä¸­çš„Prompt",
        "input_prompt": "è¾“å…¥æ‚¨çš„Prompt",
        "prompt_placeholder": "è¯·è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„Prompt...",
        "help_text": "é€‰æ‹©DeepSeekæ¨¡å‹ç‰ˆæœ¬",
        "error_no_keywords": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå…³é”®è¯ï¼",
        "error_no_companies": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå…¬å¸ï¼",
        "error_no_prompt": "è¯·è¾“å…¥Promptå†…å®¹ï¼",
        "analyzing": "æ­£åœ¨è°ƒç”¨APIåˆ†æ...",
        "step1_analyzing": "ğŸ” ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨åˆ†æè‡ªå®šä¹‰Prompt...",
        "step2_converting": "ğŸ”„ ç¬¬äºŒæ­¥ï¼šæ­£åœ¨æ ¹æ®ç•Œé¢è¯­è¨€è¦æ±‚è½¬æ¢è¾“å‡ºè¯­è¨€...",
        "language_conversion_prompt": "ğŸ”„ è¯­è¨€è½¬æ¢Prompt",
        "api_key_expired": "âŒ APIå¯†é’¥å·²è¿‡æœŸï¼Œè¯·æ›´æ–°æ‚¨çš„DeepSeek APIå¯†é’¥",
        "api_quota_exceeded": "âŒ APIé…é¢å·²ç”¨å®Œï¼Œè¯·æ£€æŸ¥æ‚¨çš„è´¦æˆ·ä½™é¢",
        "api_error": "âŒ APIè°ƒç”¨é”™è¯¯",
        "news_prompt_template": "è¯·å¸®æˆ‘æŸ¥æ‰¾{time_range}å…³äºä»¥ä¸‹å…³é”®è¯å’Œå…¬å¸çš„æœ€æ–°æ–°é—»ï¼š\n\nå…³é”®è¯ï¼š{keywords}\nå…¬å¸ï¼š{companies}\n\nå…³é”®æ—¶é—´è¦æ±‚ï¼š\n1. æ—¶é—´èŒƒå›´'{time_range}'æŒ‡çš„æ˜¯å½“å‰æ—¥æœŸå’Œæ—¶é—´ - ä¸æ˜¯ä¹‹å‰å¹´ä»½çš„å†å²æ—¥æœŸ\n2. å¦‚æœæç¤ºä¸­æåˆ°'æœ€è¿‘24å°æ—¶'ã€'æœ€è¿‘2å‘¨'ç­‰ï¼Œè¯·ä»ä»Šå¤©çš„æ—¥æœŸå¼€å§‹è®¡ç®—ï¼Œè€Œä¸æ˜¯ä»2024å¹´æˆ–ä»»ä½•å…¶ä»–è¿‡å»çš„å¹´ä»½\n3. åªæä¾›åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…ï¼ˆä»ä»Šå¤©å¼€å§‹è®¡ç®—ï¼‰å‘å¸ƒæˆ–å‘ç”Ÿçš„æ–°é—»\n4. å¦‚æœåœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æœ€æ–°æ–°é—»ï¼Œè¯·æ˜ç¡®è¯´æ˜'åœ¨{time_range}å†…æœªæ‰¾åˆ°æœ€æ–°æ–°é—»ï¼ˆä»å½“å‰æ—¥æœŸè®¡ç®—ï¼‰'ï¼Œè€Œä¸æ˜¯æä¾›æ—§ä¿¡æ¯\n5. é™¤éä¸å½“å‰å‘å±•ç‰¹åˆ«ç›¸å…³ï¼Œå¦åˆ™æ°¸è¿œä¸è¦å¼•ç”¨2024å¹´ã€2023å¹´æˆ–ä»»ä½•ä¹‹å‰å¹´ä»½çš„æ—¥æœŸ\n\nè¯·æä¾›ï¼š\n1. æ¯æ¡æ–°é—»çš„æ ‡é¢˜ã€æ¥æºã€å‘å¸ƒæ—¶é—´\n2. æ¯æ¡æ–°é—»ä¸é€‰ä¸­å…³é”®è¯å’Œå…¬å¸çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1è¡¨ç¤ºæœ€ç›¸å…³ï¼‰\n3. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥ï¼ˆå¿…é¡»æ˜¯çœŸå®å¯è®¿é—®çš„é“¾æ¥ï¼‰\n4. æ–°é—»æ‘˜è¦\n5. æ–°é—»å®Œæ•´å†…å®¹\n6. æŒ‰ç›¸å…³æ€§å’Œæ—¶æ•ˆæ€§æ’åº\n\nè¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼è¦æ¸…æ™°æ˜“è¯»ï¼Œç¡®ä¿æ‰€æœ‰æ–°é—»éƒ½æ¥è‡ªä»å½“å‰æ—¥æœŸå¼€å§‹è®¡ç®—çš„æŒ‡å®šæ—¶é—´æ®µã€‚"
    }
}

# ä¸­è‹±æ–‡å…³é”®è¯æ˜ å°„
KEYWORDS_MAPPING = {
    "en": [
        "Lithium", "Cobalt", "Nickel", "Graphite", "Manganese", "Copper", "Aluminum", "Zinc", "Gallium", "Germanium", 
        "Rare Earth", "Tungsten", "Titanium", "Vanadium", "Antimony", "Beryllium", "Zirconium", "Tantalum", "Niobium",
        "Arsenic", "Barite", "Bismuth", "Cerium", "Cesium", "Chromium", "Dysprosium", "Erbium", "Europium", "Fluorite", 
        "Gadolinium", "Hafnium", "Holmium", "Indium", "Iridium", "Lanthanum", "Lutetium", "Magnesium", "Neodymium", 
        "Palladium", "Platinum", "Praseodymium", "Rhodium", "Rubidium", "Ruthenium", "Samarium", "Scandium", "Tellurium", 
        "Terbium", "Thulium", "Tin", "Ytterbium", "Yttrium", "China-US Critical Minerals", "Geopolitical Competition Critical Minerals",
        "China-Africa Critical Minerals", "EU-China-Africa Geopolitical Competition", "Belt and Road Initiative, China and Africa", 
        "Rare Earth US, China Rare Earth", "Rare Earth China-Africa", "EU-China-Africa Critical Minerals", 
        "Refining Africa and China Critical Minerals", "China-Congo Cobalt Industry"
    ],
    "zh": [
        "é”‚", "é’´", "é•", "çŸ³å¢¨", "é”°", "é“œ", "é“", "é”Œ", "é•“", "é”—", "ç¨€åœŸ", "é’¨", "é’›", "é’’", "é”‘", "é“", "é”†", "é’½", "é“Œ",
        "ç ·", "é‡æ™¶çŸ³", "é“‹", "é“ˆ", "é“¯", "é“¬", "é•", "é“’", "é“•", "è¤çŸ³", "é’†", "é“ª", "é’¬", "é“Ÿ", "é“±", "é•§", "é•¥", "é•", 
        "é’•", "é’¯", "é“‚", "é•¨", "é“‘", "é“·", "é’Œ", "é’", "é’ª", "ç¢²", "é“½", "é“¥", "é”¡", "é•±", "é’‡", "ä¸­ç¾å…³é”®çŸ¿äº§", "åœ°ç¼˜æ”¿æ²»ç«äº‰çš„å…³é”®çŸ¿äº§",
        "ä¸­éå…³é”®çŸ¿äº§", "æ¬§ç›Ÿã€ä¸­å›½ã€éæ´²åœ°ç¼˜æ”¿æ²»ç«äº‰", "ä¸€å¸¦ä¸€è·¯å€¡è®®,ä¸­å›½å’Œéæ´²", "ç¨€åœŸç¾å›½ï¼Œä¸­å›½ç¨€åœŸ", "ç¨€åœŸä¸­å›½-éæ´²ï¼Œç¨€åœŸä¸­é", 
        "æ¬§ç›Ÿ-ä¸­å›½-éæ´²å…³é”®çŸ¿äº§", "æç‚¼éæ´²å’Œä¸­å›½çš„å…³é”®çŸ¿äº§", "ä¸­å›½-åˆšæœé’´ä¸š"
    ]
}

# ä¸­è‹±æ–‡å…¬å¸æ˜ å°„
COMPANIES_MAPPING = {
    "en": {
        "CMOC China Molybdenum / Luoyang Molybdenum Industry": "Luoyang Molybdenum Group",
        "Zijin": "Zijin Mining Group Co., Ltd.",
        "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "Chengdu Chengxin Lithium Industry Co., Ltd.",
        "Tsingshan Holding group": "Tsingshan Holding Group Co., Ltd.",
        "Huayou Cobalt": "Zhejiang Huayou Cobalt Co., Ltd.",
        "Sinomine Resources Group": "Sinomine Resources Group Co., Ltd.",
        "Sinohydro Corporation": "Sinohydro Corporation",
        "Sichuan Yahua Industrial Group": "Sichuan Yahua Industrial Group Co., Ltd.",
        "Chinalco (Aluminum Corporation of China)": "Aluminum Corporation of China Limited",
        "China Minmetals Corporation": "China Minmetals Corporation",
        "China Hongqiao group": "China Hongqiao Group Limited",
        "China Non Metals Mining Group": "China Nonferrous Metal Mining Group Co., Ltd.",
        "Jiangxi Copper Company": "Jiangxi Copper Co., Ltd.",
        "Baiyin Nonferrous Group (BNMC)": "Baiyin Nonferrous Group Co., Ltd.",
        "Hunan Nonferrous Metals Group": "Hunan Nonferrous Metals Holding Group Co., Ltd.",
        "Tibet Huayu Mining": "Tibet Huayu Mining Co., Ltd.",
        "Ganfeng Lithium": "Ganfeng Lithium Co., Ltd.",
        "Tibet Everest Resources": "Tibet Summit Resources Co., Ltd.",
        "BYD": "BYD Co., Ltd.",
        "Tianqi Lithium": "Tianqi Lithium Corporation",
        "CATL": "Contemporary Amperex Technology Co., Limited"
    },
    "zh": {
        "CMOC China Molybdenum / Luoyang Molybdenum Industry": "æ´›é’¼é›†å›¢",
        "Zijin": "ç´«é‡‘çŸ¿ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
        "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "æˆéƒ½æˆé‘«é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
        "Tsingshan Holding group": "é’å±±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸",
        "Huayou Cobalt": "æµ™æ±Ÿåå‹é’´ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
        "Sinomine Resources Group": "ä¸­çŸ¿èµ„æºé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
        "Sinohydro Corporation": "ä¸­å›½æ°´åˆ©æ°´ç”µå»ºè®¾é›†å›¢å…¬å¸",
        "Sichuan Yahua Industrial Group": "å››å·é›…åŒ–å®ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (é›…åŒ–é›†å›¢)",
        "Chinalco (Aluminum Corporation of China)": "ä¸­å›½é“ä¸šé›†å›¢æœ‰é™å…¬å¸ (ä¸­å›½é“ä¸š / ä¸­é“)",
        "China Minmetals Corporation": "ä¸­å›½äº”çŸ¿é›†å›¢æœ‰é™å…¬å¸ (äº”çŸ¿é›†å›¢)",
        "China Hongqiao group": "ä¸­å›½å®æ¡¥é›†å›¢æœ‰é™å…¬å¸",
        "China Non Metals Mining Group": "ä¸­å›½æœ‰è‰²çŸ¿ä¸šé›†å›¢æœ‰é™å…¬å¸",
        "Jiangxi Copper Company": "æ±Ÿè¥¿é“œä¸šé›†å›¢æœ‰é™å…¬å¸ (æ±Ÿè¥¿é“œä¸š)",
        "Baiyin Nonferrous Group (BNMC)": "ç™½é“¶æœ‰è‰²é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (ç™½é“¶æœ‰è‰²)",
        "Hunan Nonferrous Metals Group": "æ¹–å—æœ‰è‰²é‡‘å±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸ (æ¹–å—æœ‰è‰²)",
        "Tibet Huayu Mining": "è¥¿è—åé’°çŸ¿ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (åé’°çŸ¿ä¸š)",
        "Ganfeng Lithium": "èµ£ä¸°é”‚ä¸š",
        "Tibet Everest Resources": "è¥¿è—ç å³°èµ„æºè‚¡ä»½æœ‰é™å…¬å¸",
        "BYD": "æ¯”äºšè¿ªè‚¡ä»½æœ‰é™å…¬å¸ (æ¯”äºšè¿ª)",
        "Tianqi Lithium": "å¤©é½é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (å¤©é½é”‚ä¸š)",
        "CATL": "å®å¾·æ—¶ä»£æ–°èƒ½æºç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ (å®å¾·æ—¶ä»£)"
    }
}

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="Critical Minerals News Analysis System",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è¯­è¨€é€‰æ‹©å™¨ï¼ˆé»˜è®¤è‹±æ–‡ï¼‰
if 'language' not in st.session_state:
    st.session_state.language = 'en'

# ä¾§è¾¹æ è¯­è¨€åˆ‡æ¢
with st.sidebar:
    st.header("ğŸŒ Language / è¯­è¨€")
    selected_language = st.selectbox(
        "Select Language / é€‰æ‹©è¯­è¨€",
        options=[("en", "English"), ("zh", "ä¸­æ–‡")],
        index=0 if st.session_state.language == 'en' else 1,
        format_func=lambda x: x[1]
    )
    
    if selected_language[0] != st.session_state.language:
        st.session_state.language = selected_language[0]
        st.rerun()
    
    # åˆå§‹åŒ–å†å²è®°å½•
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    
    # å†å²è®°å½•ç®¡ç†å‡½æ•°
    def add_to_history(keywords, companies, time_option, result, prompt):
        """æ·»åŠ æœç´¢ç»“æœåˆ°å†å²è®°å½•"""
        current_date = datetime.now()
        date_str = current_date.strftime('%Y-%m-%d %H:%M')
        
        # æ„å»ºæ ‡é¢˜
        keywords_str = ", ".join(keywords) if keywords else ("æ— å…³é”®è¯" if st.session_state.language == "zh" else "No Keywords")
        companies_str = ", ".join(companies) if companies else ("æ— å…¬å¸" if st.session_state.language == "zh" else "No Companies")
        
        if st.session_state.language == "zh":
            title = f"{date_str} - {keywords_str} - {companies_str}"
        else:
            title = f"{date_str} - {keywords_str} - {companies_str}"
        
        # åˆ›å»ºå†å²è®°å½•é¡¹
        history_item = {
            'id': len(st.session_state.search_history),
            'title': title,
            'date': date_str,
            'keywords': keywords,
            'companies': companies,
            'time_option': time_option,
            'result': result,
            'prompt': prompt,
            'language': st.session_state.language
        }
        
        # æ·»åŠ åˆ°å†å²è®°å½•å¼€å¤´
        st.session_state.search_history.insert(0, history_item)
        
        # ä¿æŒæœ€å¤š10æ¡è®°å½•
        if len(st.session_state.search_history) > 10:
            st.session_state.search_history = st.session_state.search_history[:10]
    

    
    # å†å²è®°å½•é€‰æ‹©å™¨
    st.markdown("---")
    st.subheader("ğŸ“š æœç´¢å†å²" if st.session_state.language == "zh" else "ğŸ“š Search History")
    
    if st.session_state.search_history:
        # åˆ›å»ºå†å²è®°å½•é€‰æ‹©å™¨
        history_titles = [item['title'] for item in st.session_state.search_history]
        selected_history = st.selectbox(
            "é€‰æ‹©å†å²è®°å½•" if st.session_state.language == "zh" else "Select History Record",
            options=history_titles,
            index=0
        )
        
        # ä¿å­˜é€‰ä¸­çš„å†å²è®°å½•åˆ°session state
        selected_item = next((item for item in st.session_state.search_history if item['title'] == selected_history), None)
        if selected_item:
            st.session_state.selected_history_item = selected_item
    else:
        st.info("æš‚æ— æœç´¢å†å²" if st.session_state.language == "zh" else "No search history yet")
        st.session_state.selected_history_item = None

# è·å–å½“å‰è¯­è¨€
lang = LANGUAGES[st.session_state.language]

# æ ¹æ®è¯­è¨€è·å–å…³é”®è¯å’Œå…¬å¸
KEYWORDS = KEYWORDS_MAPPING[st.session_state.language]
COMPANIES = COMPANIES_MAPPING[st.session_state.language]

TIME_OPTIONS = lang["time_options"]

# ç¡®ä¿å…³é”®è¯å’Œå…¬å¸åˆ—è¡¨æ ¹æ®è¯­è¨€åŠ¨æ€æ›´æ–°
def get_localized_options():
    """è·å–æœ¬åœ°åŒ–çš„é€‰é¡¹åˆ—è¡¨"""
    current_lang = st.session_state.language
    return {
        "keywords": KEYWORDS_MAPPING[current_lang],
        "companies": list(COMPANIES_MAPPING[current_lang].keys()),
        "time_options": LANGUAGES[current_lang]["time_options"]
    }

# API é…ç½® - ä» secrets.toml æ–‡ä»¶è¯»å–
try:
    SERPAPI_API_KEY = st.secrets["SERPAPI_API_KEY"]
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except KeyError as e:
    st.error(f"âŒ é…ç½®é”™è¯¯: åœ¨ .streamlit/secrets.toml æ–‡ä»¶ä¸­ç¼ºå°‘ API å¯†é’¥: {e}")
    st.stop()
except Exception as e:
    st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    st.stop()

# é¢„å®šä¹‰æ•°æ®
KEYWORDS = [
    "é”‚", "é’´", "é•", "çŸ³å¢¨", "é”°", "é“œ", "é“", "é”Œ", "é•“", "é”—", "ç¨€åœŸ", "é’¨", "é’›", "é’’", "é”‘", "é“", "é”†", "é’½", "é“Œ",
    "ç ·", "é‡æ™¶çŸ³", "é“‹", "é“ˆ", "é“¯", "é“¬", "é•", "é“’", "é“•", "è¤çŸ³", "é’†", "é“ª", "é’¬", "é“Ÿ", "é“±", "é•§", "é•¥", "é•", 
    "é’•", "é’¯", "é“‚", "é•¨", "é“‘", "é“·", "é’Œ", "é’", "é’ª", "ç¢²", "é“½", "é“¥", "é”¡", "é•±", "é’‡",     "ä¸­ç¾å…³é”®çŸ¿äº§", "åœ°ç¼˜æ”¿æ²»ç«äº‰çš„å…³é”®çŸ¿äº§",
    "ä¸­éå…³é”®çŸ¿äº§", "æ¬§ç›Ÿã€ä¸­å›½ã€éæ´²åœ°ç¼˜æ”¿æ²»ç«äº‰", "ä¸€å¸¦ä¸€è·¯å€¡è®®,ä¸­å›½å’Œéæ´²", "ç¨€åœŸç¾å›½ï¼Œä¸­å›½ç¨€åœŸ", "ç¨€åœŸä¸­å›½-éæ´²ï¼Œç¨€åœŸä¸­é", 
    "æ¬§ç›Ÿ-ä¸­å›½-éæ´²å…³é”®çŸ¿äº§", "æç‚¼éæ´²å’Œä¸­å›½çš„å…³é”®çŸ¿äº§", "ä¸­å›½-åˆšæœé’´ä¸š"
]

COMPANIES = {
    "CMOC China Molybdenum / Luoyang Molybdenum Industry": "æ´›é’¼é›†å›¢",
    "Zijin": "ç´«é‡‘çŸ¿ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
    "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "æˆéƒ½æˆé‘«é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
    "Tsingshan Holding group": "é’å±±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸",
    "Huayou Cobalt": "æµ™æ±Ÿåå‹é’´ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
    "Sinomine Resources Group": "ä¸­çŸ¿èµ„æºé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
    "Sinohydro Corporation": "ä¸­å›½æ°´åˆ©æ°´ç”µå»ºè®¾é›†å›¢å…¬å¸",
    "Sichuan Yahua Industrial Group": "å››å·é›…åŒ–å®ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (é›…åŒ–é›†å›¢)",
    "Chinalco (Aluminum Corporation of China)": "ä¸­å›½é“ä¸šé›†å›¢æœ‰é™å…¬å¸ (ä¸­å›½é“ä¸š / ä¸­é“)",
    "China Minmetals Corporation": "ä¸­å›½äº”çŸ¿é›†å›¢æœ‰é™å…¬å¸ (äº”çŸ¿é›†å›¢)",
    "China Hongqiao group": "ä¸­å›½å®æ¡¥é›†å›¢æœ‰é™å…¬å¸",
    "China Non Metals Mining Group": "ä¸­å›½æœ‰è‰²çŸ¿ä¸šé›†å›¢æœ‰é™å…¬å¸",
    "Jiangxi Copper Company": "æ±Ÿè¥¿é“œä¸šé›†å›¢æœ‰é™å…¬å¸ (æ±Ÿè¥¿é“œä¸š)",
    "Baiyin Nonferrous Group (BNMC)": "ç™½é“¶æœ‰è‰²é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (ç™½é“¶æœ‰è‰²)",
    "Hunan Nonferrous Metals Group": "æ¹–å—æœ‰è‰²é‡‘å±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸ (æ¹–å—æœ‰è‰²)",
    "Tibet Huayu Mining": "è¥¿è—åé’°çŸ¿ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (åé’°çŸ¿ä¸š)",
    "Ganfeng Lithium": "èµ£ä¸°é”‚ä¸š",
    "Tibet Everest Resources": "è¥¿è—ç å³°èµ„æºè‚¡ä»½æœ‰é™å…¬å¸",
    "BYD": "æ¯”äºšè¿ªè‚¡ä»½æœ‰é™å…¬å¸ (æ¯”äºšè¿ª)",
    "Tianqi Lithium": "å¤©é½é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (å¤©é½é”‚ä¸š)",
    "CATL": "å®å¾·æ—¶ä»£æ–°èƒ½æºç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ (å®å¾·æ—¶ä»£)"
}

TIME_OPTIONS = {
    "æœ€è¿‘2å‘¨": "2_weeks",
    "æœ€è¿‘2å¤©": "2_days",
    "è‡ªå®šä¹‰æ—¶é—´åŒºé—´": "custom"
}

def generate_news_prompt(selected_keywords, selected_companies, time_option, custom_start_date=None, custom_end_date=None):
    """ç”Ÿæˆæœç´¢å‚æ•°æè¿°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰"""
    current_date = datetime.now()
    
    # æ„å»ºå…³é”®è¯æ˜¾ç¤º
    if selected_keywords:
        keywords_str = ", ".join(selected_keywords)
        keywords_display = f"Keywords: {keywords_str}" if st.session_state.language == "en" else f"å…³é”®è¯: {keywords_str}"
    else:
        keywords_display = "Keywords: Not specified" if st.session_state.language == "en" else "å…³é”®è¯: æœªæŒ‡å®š"
    
    # æ„å»ºå…¬å¸æ˜¾ç¤º
    if selected_companies:
        current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
        predefined_companies = [comp for comp in selected_companies if comp in current_companies_mapping]
        custom_companies = [comp for comp in selected_companies if comp not in current_companies_mapping]
        
        companies_parts = []
        if predefined_companies:
            companies_parts.append(f"Predefined companies: {', '.join(predefined_companies)}" if st.session_state.language == "en" else f"é¢„å®šä¹‰å…¬å¸: {', '.join(predefined_companies)}")
        if custom_companies:
            companies_parts.append(f"Custom companies: {', '.join(custom_companies)}" if st.session_state.language == "en" else f"è‡ªå®šä¹‰å…¬å¸: {', '.join(custom_companies)}")
        
        companies_display = "; ".join(companies_parts)
    else:
        companies_display = "Companies: Not specified" if st.session_state.language == "en" else "å…¬å¸: æœªæŒ‡å®š"
    
    # æ„å»ºæ—¶é—´å­—ç¬¦ä¸²
    if time_option == "2_weeks":
        start_date = current_date - timedelta(weeks=2)
        if st.session_state.language == "en":
            time_str = f"last 2 weeks ({start_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')})"
        else:
            time_str = f"æœ€è¿‘2å‘¨ï¼ˆ{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼‰"
    elif time_option == "2_days":
        start_date = current_date - timedelta(days=2)
        if st.session_state.language == "en":
            time_str = f"last 2 days ({start_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')})"
        else:
            time_str = f"æœ€è¿‘2å¤©ï¼ˆ{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼‰"
    elif time_option == "custom" and custom_start_date and custom_end_date:
        if st.session_state.language == "en":
            time_str = f"custom time range ({custom_start_date} to {custom_end_date})"
        else:
            time_str = f"è‡ªå®šä¹‰æ—¶é—´åŒºé—´ï¼ˆ{custom_start_date} è‡³ {custom_end_date}ï¼‰"
    else:
        time_str = "recent time period" if st.session_state.language == "en" else "æœ€è¿‘æ—¶é—´æ®µ"
    
    # æ„å»ºæœç´¢èŒƒå›´æè¿°
    if selected_keywords and selected_companies:
        search_scope = f"news about {keywords_display} or {companies_display}" if st.session_state.language == "en" else f"å…³äº{keywords_display}æˆ–{companies_display}çš„æ–°é—»"
    elif selected_keywords:
        search_scope = f"news about {keywords_display}" if st.session_state.language == "en" else f"å…³äº{keywords_display}çš„æ–°é—»"
    elif selected_companies:
        search_scope = f"news about {companies_display}" if st.session_state.language == "en" else f"å…³äº{companies_display}çš„æ–°é—»"
    else:
        search_scope = "news" if st.session_state.language == "en" else "æ–°é—»"
    
    # ç”Ÿæˆæœç´¢å‚æ•°æè¿°
    if st.session_state.language == "en":
        prompt = f"""Search Parameters:
- Search Scope: {search_scope}
- Time Range: {time_str}
- Current Date: {current_date.strftime('%Y-%m-%d')}
- Search Engine: Baidu News (via SerpApi) â†’ OpenAI Formatting
- Logic: OR (news content is relevant if it matches ANY keyword OR ANY company)

{keywords_display}
{companies_display}

The system will: 1) Search for real news articles via SerpApi, 2) Format output with OpenAI using the following 7 fields for each news item:
1. Title: Complete news title
2. Relevance: Relevance score (0-1, 1 being most relevant)
3. Source: News source (from Chinese media)
4. Source Link: URL link to the original news article (real and accessible)
5. Publish Time: Specific publication time (YYYY-MM-DD HH:MM)
6. Summary: Brief overview (100-200 words)
7. Full Text: Complete news content"""
    else:
        prompt = f"""æœç´¢å‚æ•°ï¼š
- æœç´¢èŒƒå›´ï¼š{search_scope}
- æ—¶é—´èŒƒå›´ï¼š{time_str}
- å½“å‰æ—¥æœŸï¼š{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}
- æœç´¢å¼•æ“ï¼šç™¾åº¦æ–°é—»ï¼ˆé€šè¿‡SerpApiï¼‰â†’ OpenAIæ ¼å¼åŒ–
- é€»è¾‘ï¼šæˆ–ï¼ˆæ–°é—»å†…å®¹ä¸ä»»ä¸€å…³é”®è¯æˆ–ä»»ä¸€å…¬å¸ç›¸å…³å³å¯ï¼‰

{keywords_display}
{companies_display}

ç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢çœŸå®æ–°é—»æ–‡ç« ï¼Œ2ï¼‰ä½¿ç”¨OpenAIæ ¼å¼åŒ–è¾“å‡ºï¼Œä¸ºæ¯æ¡æ–°é—»æä¾›ä»¥ä¸‹7ä¸ªå­—æ®µçš„åˆ†æï¼š
1. æ ‡é¢˜ï¼šæ–°é—»çš„å®Œæ•´æ ‡é¢˜
2. ç›¸å…³æ€§ï¼šç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1ä¸ºæœ€ç›¸å…³ï¼‰
3. æ¥æºï¼šæ–°é—»æ¥æºï¼ˆæ¥è‡ªä¸­å›½åª’ä½“ï¼‰
4. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥ï¼ˆçœŸå®å¯è®¿é—®ï¼‰
5. å‘å¸ƒæ—¶é—´ï¼šå…·ä½“å‘å¸ƒæ—¶é—´ï¼ˆå¹´-æœˆ-æ—¥ æ—¶:åˆ†ï¼‰
6. æ‘˜è¦ï¼šç®€è¦æ¦‚è¿°ï¼ˆ100-200å­—ï¼‰
7. å…¨æ–‡ï¼šæ–°é—»å®Œæ•´å†…å®¹"""
    
    return prompt

def generate_language_conversion_prompt(news_content, target_language):
    """ç”Ÿæˆè¯­è¨€è½¬æ¢Prompt - ç¬¬äºŒæ­¥ï¼šæ ¹æ®UIè¯­è¨€è¦æ±‚è½¬æ¢è¾“å‡ºè¯­è¨€"""
    if target_language == "en":
        prompt = f"""You are a professional news content translator and formatter. Please convert the following Chinese news analysis to English while maintaining the exact same structure and format.

âš ï¸ CRITICAL REQUIREMENTS:
- Convert ALL Chinese text to English
- Keep the exact same 7-field format: Title, Relevance, Source, Source Link, Publish Time, Summary, Full Text
- Maintain red bold formatting for field labels: <span style="color: #ff0000; font-weight: bold;">**Field Name**</span>
- Keep the same line breaks and spacing between fields
- Preserve all news content and relevance scores
- Ensure professional English translation

Original Chinese content:
{news_content}

Please provide the English version with the exact same format and structure."""
    else:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»å†…å®¹ç¿»è¯‘å’Œæ ¼å¼åŒ–ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»åˆ†æè½¬æ¢ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒå®Œå…¨ç›¸åŒçš„ç»“æ„å’Œæ ¼å¼ã€‚

âš ï¸ é‡è¦è¦æ±‚ï¼š
- å°†æ‰€æœ‰è‹±æ–‡æ–‡æœ¬è½¬æ¢ä¸ºä¸­æ–‡
- ä¿æŒå®Œå…¨ç›¸åŒçš„7å­—æ®µæ ¼å¼ï¼šæ ‡é¢˜ã€ç›¸å…³æ€§ã€æ¥æºã€æ¥æºé“¾æ¥ã€å‘å¸ƒæ—¶é—´ã€æ‘˜è¦ã€å…¨æ–‡
- ä¿æŒå­—æ®µæ ‡ç­¾çš„çº¢è‰²åŠ ç²—æ ¼å¼ï¼š<span style="color: #ff0000; font-weight: bold;">**å­—æ®µå**</span>
- ä¿æŒç›¸åŒçš„æ¢è¡Œå’Œå­—æ®µé—´é—´è·
- ä¿ç•™æ‰€æœ‰æ–°é—»å†…å®¹å’Œç›¸å…³æ€§è¯„åˆ†
- ç¡®ä¿ä¸“ä¸šçš„ä¸­æ–‡ç¿»è¯‘

åŸå§‹è‹±æ–‡å†…å®¹ï¼š
{news_content}

è¯·æä¾›ä¸­æ–‡ç‰ˆæœ¬ï¼Œä¿æŒå®Œå…¨ç›¸åŒçš„æ ¼å¼å’Œç»“æ„ã€‚"""
    
    return prompt

def search_baidu_news(keywords, companies, time_option, custom_start_date=None, custom_end_date=None):
    """ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼ˆç¬¬ä¸€æ­¥ï¼‰"""
    try:
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_terms = []
        
        # æ·»åŠ å…³é”®è¯
        if keywords:
            search_terms.extend(keywords)
        
        # æ·»åŠ å…¬å¸åç§°
        if companies:
            # è·å–å½“å‰è¯­è¨€çš„å…¬å¸æ˜ å°„
            current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
            for company in companies:
                if company in current_companies_mapping:
                    # ä½¿ç”¨é¢„å®šä¹‰å…¬å¸çš„ä¸­æ–‡åç§°è¿›è¡Œæœç´¢
                    search_terms.append(current_companies_mapping[company])
                else:
                    # ä½¿ç”¨è‡ªå®šä¹‰å…¬å¸åç§°
                    search_terms.append(company)
        
        # æ„å»ºæœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        query = " OR ".join(search_terms) if search_terms else "å…³é”®çŸ¿äº§"
        
        # æ·»åŠ æ—¶é—´èŒƒå›´é™åˆ¶
        current_date = datetime.now()
        if time_option == "2_weeks":
            start_date = current_date - timedelta(weeks=2)
            date_range = f" {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        elif time_option == "2_days":
            start_date = current_date - timedelta(days=2)
            date_range = f" {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        elif time_option == "custom" and custom_start_date and custom_end_date:
            date_range = f" {custom_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{custom_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        else:
            date_range = ""
        
        # æœ€ç»ˆæœç´¢æŸ¥è¯¢
        final_query = query + date_range
        
        # ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
        search = GoogleSearch({
            "engine": "baidu_news",
            "q": final_query,
            "api_key": SERPAPI_API_KEY,
            "medium":1,
            "rtt":4,
            "num": 8  # è·å–å‰8æ¡ç»“æœ
        })
        
        results = search.get_dict()
        
        # å¤„ç†æœç´¢ç»“æœ
        if "organic_results" in results and results["organic_results"]:
            return results["organic_results"]  # è¿”å›åŸå§‹æœç´¢ç»“æœ
        else:
            return None  # è¿”å›Noneè¡¨ç¤ºæœªæ‰¾åˆ°ç»“æœ
            
    except Exception as e:
        raise Exception(f"æœç´¢å¤±è´¥: {str(e)}")

def scrape_web_content(url, max_retries=3):
    """æŠ“å–ç½‘é¡µå†…å®¹"""
    try:
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        for attempt in range(max_retries):
            try:
                # å‘é€è¯·æ±‚
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()
                
                # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' not in content_type:
                    return f"âŒ æ— æ³•è·å–HTMLå†…å®¹ï¼Œå†…å®¹ç±»å‹: {content_type}"
                
                # è§£æHTML
                soup = BeautifulSoup(response.content, 'lxml')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
                for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    script.decompose()
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ¥æ‰¾åˆ°ä¸»è¦å†…å®¹
                content_selectors = [
                    'article',
                    '.article-content',
                    '.content',
                    '.news-content',
                    '.post-content',
                    '.entry-content',
                    'main',
                    '.main-content',
                    '#content',
                    '.article-body',
                    '.news-body'
                ]
                
                content_text = ""
                for selector in content_selectors:
                    elements = soup.select(selector)
                    if elements:
                        content_text = ' '.join([elem.get_text(strip=True) for elem in elements])
                        if len(content_text) > 100:  # ç¡®ä¿å†…å®¹è¶³å¤Ÿé•¿
                            break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå†…å®¹åŒºåŸŸï¼Œå°è¯•è·å–bodyå†…å®¹
                if not content_text or len(content_text) < 100:
                    body = soup.find('body')
                    if body:
                        content_text = body.get_text(strip=True)
                
                # æ¸…ç†æ–‡æœ¬
                if content_text:
                    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
                    content_text = re.sub(r'\s+', ' ', content_text)
                    # é™åˆ¶é•¿åº¦ï¼ˆé¿å…è¿‡é•¿çš„å†…å®¹ï¼‰
                    if len(content_text) > 5000:
                        content_text = content_text[:5000] + "..."
                    return content_text
                else:
                    return "âŒ æ— æ³•æå–ç½‘é¡µå†…å®¹"
                    
            except requests.exceptions.RequestException as e:
                if attempt < max_retries - 1:
                    time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                else:
                    return f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    return f"âŒ è§£æå¤±è´¥: {str(e)}"
                    
    except Exception as e:
        return f"âŒ æŠ“å–å¤±è´¥: {str(e)}"

def fix_html_rendering(content):
    """ä¿®å¤HTMLæ¸²æŸ“é—®é¢˜ï¼Œç¡®ä¿HTMLæ ‡ç­¾è¢«æ­£ç¡®æ˜¾ç¤º"""
    import html
    
    # å¦‚æœå†…å®¹è¢«HTMLè½¬ä¹‰äº†ï¼Œå…ˆè§£ç 
    if '&lt;' in content or '&gt;' in content or '&amp;' in content:
        content = html.unescape(content)
    
    # ç¡®ä¿spanæ ‡ç­¾æ ¼å¼æ­£ç¡®
    content = content.replace('&lt;span', '<span')
    content = content.replace('&lt;/span&gt;', '</span>')
    content = content.replace('&quot;', '"')
    
    return content

def analyze_news_with_openai(news_results, keywords, companies):
    """ä½¿ç”¨OpenAIåˆ†ææ–°é—»æœç´¢ç»“æœï¼ˆç¬¬äºŒæ­¥ï¼šæ ¼å¼åŒ–è¾“å‡ºï¼‰"""
    try:
        # ä¸ºæ¯ä¸ªæ–°é—»æ¡ç›®æŠ“å–å®Œæ•´å†…å®¹
        enhanced_news_results = []
        
        for i, news_item in enumerate(news_results[:6]):  # åªå¤„ç†å‰6æ¡æ–°é—»
            enhanced_item = news_item.copy()
            
            # è·å–æ–°é—»é“¾æ¥
            news_url = news_item.get('link', '')
            
            if news_url and validate_url(news_url)[0]:
                # æ˜¾ç¤ºæŠ“å–è¿›åº¦
                if hasattr(st, 'session_state') and hasattr(st.session_state, 'language'):
                    current_lang = st.session_state.language
                    progress_text = f"ğŸ” æ­£åœ¨æŠ“å–ç¬¬{i+1}æ¡æ–°é—»å†…å®¹..." if current_lang == "zh" else f"ğŸ” Scraping content for news item {i+1}..."
                    if hasattr(st, 'info'):
                        st.info(progress_text)
                
                # æŠ“å–ç½‘é¡µå†…å®¹
                full_text = scrape_web_content(news_url)
                enhanced_item['full_text'] = full_text
            else:
                enhanced_item['full_text'] = "âŒ æ— æ•ˆé“¾æ¥æˆ–æ— æ³•è®¿é—®"
            
            enhanced_news_results.append(enhanced_item)
        
        # æ„å»ºåˆ†æprompt
        current_lang = st.session_state.language if hasattr(st, 'session_state') and 'language' in st.session_state else "zh"
        
        if current_lang == "zh":
            analysis_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ç™¾åº¦æ–°é—»æœç´¢ç»“æœï¼Œä¸ºæ¯æ¡æ–°é—»æä¾›è¯¦ç»†çš„åˆ†æå’Œæ ¼å¼åŒ–è¾“å‡ºã€‚

é‡è¦è¯´æ˜ï¼š
1. è¯·ç¡®ä¿æ‰€æœ‰è¾“å‡ºå†…å®¹éƒ½æ˜¯ä¸­æ–‡ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€å…¨æ–‡ç­‰æ‰€æœ‰å­—æ®µ
2. è¯·ç›´æ¥è¾“å‡ºHTMLæ ¼å¼ï¼Œä¸è¦è½¬ä¹‰HTMLæ ‡ç­¾
3. ä½¿ç”¨ä»¥ä¸‹HTMLæ ¼å¼æ¥æ ‡è®°å­—æ®µæ ‡é¢˜ï¼š<span style="color: #ff0000; font-weight: bold;">**å­—æ®µå**</span>

æœç´¢å…³é”®è¯ï¼š{', '.join(keywords) if keywords else 'æ— '}
æœç´¢å…¬å¸ï¼š{', '.join(companies) if companies else 'æ— '}

è¯·ä¸ºæ¯æ¡æ–°é—»æä¾›ä»¥ä¸‹7ä¸ªå­—æ®µçš„è¯¦ç»†åˆ†æï¼š

1. æ ‡é¢˜ï¼šæ–°é—»çš„å®Œæ•´æ ‡é¢˜ï¼ˆä¿æŒåŸæ ‡é¢˜ï¼Œå¦‚æœæ˜¯è‹±æ–‡æ ‡é¢˜åˆ™ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰
2. ç›¸å…³æ€§ï¼šç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1ä¸ºæœ€ç›¸å…³ï¼‰ï¼ŒåŸºäºä¸å…³é”®è¯å’Œå…¬å¸çš„åŒ¹é…åº¦
3. æ¥æºï¼šæ–°é—»æ¥æºï¼ˆå¿…é¡»æ¥è‡ªä¸­å›½åª’ä½“ï¼‰
4. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥
5. å‘å¸ƒæ—¶é—´ï¼šå…·ä½“å‘å¸ƒæ—¶é—´ï¼ˆå¹´-æœˆ-æ—¥ æ—¶:åˆ†ï¼‰
6. æ‘˜è¦ï¼šæ–°é—»çš„ç®€è¦æ¦‚è¿°ï¼ˆ100-200å­—ï¼Œå¿…é¡»ç”¨ä¸­æ–‡ï¼‰
7. å…¨æ–‡ï¼šæ–°é—»çš„å®Œæ•´å†…å®¹ï¼ˆå¦‚æœæŠ“å–æˆåŠŸï¼Œè¯·å°†æŠ“å–åˆ°çš„å†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼›å¦‚æœæŠ“å–å¤±è´¥ï¼Œè¯·åŸºäºæ ‡é¢˜å’Œæ‘˜è¦ç”Ÿæˆåˆç†çš„ä¸­æ–‡å†…å®¹ï¼‰

æ–°é—»æœç´¢ç»“æœï¼ˆåŒ…å«æŠ“å–çš„å®Œæ•´å†…å®¹ï¼‰ï¼š
{json.dumps(enhanced_news_results, ensure_ascii=False, indent=2)}

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
<span style="color: #ff0000; font-weight: bold;">**æ ‡é¢˜**</span>: [æ–°é—»æ ‡é¢˜]

<span style="color: #ff0000; font-weight: bold;">**ç›¸å…³æ€§**</span>: [0-1åˆ†å€¼]

<span style="color: #ff0000; font-weight: bold;">**æ¥æº**</span>: [æ–°é—»æ¥æº]

<span style="color: #ff0000; font-weight: bold;">**æ¥æºé“¾æ¥**</span>: [URLé“¾æ¥]

<span style="color: #ff0000; font-weight: bold;">**å‘å¸ƒæ—¶é—´**</span>: [æ—¶é—´]

<span style="color: #ff0000; font-weight: bold;">**æ‘˜è¦**</span>: [æ‘˜è¦å†…å®¹]

<span style="color: #ff0000; font-weight: bold;">**å…¨æ–‡**</span>: [å…¨æ–‡å†…å®¹]

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦è½¬ä¹‰HTMLæ ‡ç­¾ã€‚"""
        else:
            analysis_prompt = f"""You are a professional news analyst. Please analyze the following Baidu news search results and provide detailed analysis for each news item.

IMPORTANT Instructions:
1. Please ensure ALL output content is in English, including titles, summaries, full text, and all other fields
2. Please output HTML format directly, do NOT escape HTML tags
3. Use this HTML format for field headers: <span style="color: #ff0000; font-weight: bold;">**Field Name**</span>

Search Keywords: {', '.join(keywords) if keywords else 'None'}
Search Companies: {', '.join(companies) if companies else 'None'}

Please provide detailed analysis for each news item with the following 7 fields:

1. Title: Complete news title (translate Chinese titles to English if necessary)
2. Relevance: Relevance score (0-1, 1 being most relevant), based on match with keywords and companies
3. Source: News source (must be from Chinese media, keep original Chinese name)
4. Source Link: URL link to the original news article
5. Publish Time: Specific publication time (YYYY-MM-DD HH:MM)
6. Summary: Brief overview (100-200 words, must be in English)
7. Full Text: Complete news content (if scraping successful, translate the scraped content to English; if scraping failed, generate reasonable English content based on title and snippet)

News search results (with scraped full content):
{json.dumps(enhanced_news_results, ensure_ascii=False, indent=2)}

Output format example:
<span style="color: #ff0000; font-weight: bold;">**Title**</span>: [News title]

<span style="color: #ff0000; font-weight: bold;">**Relevance**</span>: [0-1 score]

<span style="color: #ff0000; font-weight: bold;">**Source**</span>: [News source]

<span style="color: #ff0000; font-weight: bold;">**Source Link**</span>: [URL link]

<span style="color: #ff0000; font-weight: bold;">**Publish Time**</span>: [Time]

<span style="color: #ff0000; font-weight: bold;">**Summary**</span>: [Summary content]

<span style="color: #ff0000; font-weight: bold;">**Full Text**</span>: [Full text content]

---

Please strictly follow the above format and do NOT escape HTML tags."""
        
        # è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ
        analysis_result = call_openai_api(analysis_prompt)
        
        # ä¿®å¤HTMLæ¸²æŸ“é—®é¢˜
        analysis_result = fix_html_rendering(analysis_result)
        
        return analysis_result
        
    except Exception as e:
        # å¦‚æœOpenAIåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ ¼å¼åŒ–æ–¹æ³•
        return format_news_results(news_results, keywords, companies)

def format_news_results(news_results, keywords, companies):
    """æ ¼å¼åŒ–æ–°é—»æœç´¢ç»“æœ"""
    formatted_results = []
    
    # è·å–å½“å‰è¯­è¨€è®¾ç½®
    current_lang = st.session_state.language if hasattr(st, 'session_state') and hasattr(st.session_state, 'language') else "zh"
    
    for i, news in enumerate(news_results[:5]):  # é™åˆ¶æ˜¾ç¤ºå‰5æ¡æ–°é—»
        # è®¡ç®—ç›¸å…³æ€§è¯„åˆ†
        relevance_score = calculate_relevance_score(news, keywords, companies)
        
        # æ ¹æ®è¯­è¨€è®¾ç½®æ ¼å¼åŒ–å•æ¡æ–°é—»
        if current_lang == "zh":
            news_item = f"""<span style="color: #ff0000; font-weight: bold;">**Titleï¼ˆæ ‡é¢˜ï¼‰**</span>: {news.get('title', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Relevanceï¼ˆç›¸å…³æ€§ï¼‰**</span>: {relevance_score:.2f}

<span style="color: #ff0000; font-weight: bold;">**Sourceï¼ˆæ¥æºï¼‰**</span>: {news.get('source', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Source Linkï¼ˆæ¥æºé“¾æ¥ï¼‰**</span>: {news.get('link', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Publish Timeï¼ˆå‘å¸ƒæ—¶é—´ï¼‰**</span>: {news.get('date', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Summaryï¼ˆæ‘˜è¦ï¼‰**</span>: {news.get('snippet', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Full Textï¼ˆå…¨æ–‡ï¼‰**</span>: {news.get('snippet', 'N/A')}

---
"""
        else:
            news_item = f"""<span style="color: #ff0000; font-weight: bold;">**Title**</span>: {news.get('title', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Relevance**</span>: {relevance_score:.2f}

<span style="color: #ff0000; font-weight: bold;">**Source**</span>: {news.get('source', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Source Link**</span>: {news.get('link', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Publish Time**</span>: {news.get('date', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Summary**</span>: {news.get('snippet', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Full Text**</span>: {news.get('snippet', 'N/A')}

---
"""
        formatted_results.append(news_item)
    
    return "\n".join(formatted_results)

def calculate_relevance_score(news, keywords, companies):
    """è®¡ç®—æ–°é—»ç›¸å…³æ€§è¯„åˆ†"""
    score = 0.0
    title = news.get('title', '').lower()
    snippet = news.get('snippet', '').lower()
    content = f"{title} {snippet}"
    
    # å…³é”®è¯åŒ¹é…
    if keywords:
        keyword_matches = sum(1 for keyword in keywords if keyword.lower() in content)
        score += (keyword_matches / len(keywords)) * 0.6
    
    # å…¬å¸åŒ¹é…
    if companies:
        company_matches = 0
        current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
        for company in companies:
            if company in current_companies_mapping:
                company_name = current_companies_mapping[company].lower()
                if company_name in content:
                    company_matches += 1
            else:
                if company.lower() in content:
                    company_matches += 1
        score += (company_matches / len(companies)) * 0.4
    
    # ç¡®ä¿è¯„åˆ†åœ¨0-1ä¹‹é—´
    return min(max(score, 0.1), 1.0)

def extract_search_terms_from_prompt(prompt):
    """ä»è‡ªå®šä¹‰promptä¸­æå–å…³é”®è¯å’Œå…¬å¸ä¿¡æ¯"""
    keywords = []
    companies = []
    
    # è·å–å½“å‰è¯­è¨€çš„å…³é”®è¯å’Œå…¬å¸åˆ—è¡¨
    current_keywords = KEYWORDS_MAPPING[st.session_state.language]
    current_companies = list(COMPANIES_MAPPING[st.session_state.language].keys())
    
    prompt_lower = prompt.lower()
    
    # æå–å…³é”®è¯
    for keyword in current_keywords:
        if keyword.lower() in prompt_lower:
            keywords.append(keyword)
    
    # æå–å…¬å¸
    for company in current_companies:
        if company.lower() in prompt_lower:
            companies.append(company)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„å®šä¹‰çš„å…³é”®è¯æˆ–å…¬å¸ï¼Œä½¿ç”¨ä¸€äº›é€šç”¨å…³é”®è¯
    if not keywords and not companies:
        keywords = ["å…³é”®çŸ¿äº§", "çŸ¿ä¸š"] if st.session_state.language == "zh" else ["critical minerals", "mining"]
    
    return keywords, companies

def call_openai_api(prompt, model="gpt-4o"):
    """è°ƒç”¨OpenAI API (ç”¨äºè¯­è¨€è½¬æ¢å’Œå†…å®¹åˆ†æ)"""
    try:
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=OPENAI_API_KEY,
        )
        
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=4096,
            stream=False
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "unauthorized" in error_msg.lower():
            return "âŒ APIè°ƒç”¨å¤±è´¥: æ‚¨çš„OpenAI APIå¯†é’¥å·²è¿‡æœŸæˆ–æ— æ•ˆï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®ã€‚"
        elif "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
            return "âŒ APIè°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°OpenAI APIè°ƒç”¨é…é¢é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ã€‚"
        else:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}"

def main():
    st.title(lang["title"])
    st.markdown("---")
    
    # åˆ›å»ºä¸‰ä¸ªTabé¡µ
    tab1, tab2, tab3 = st.tabs([lang["tab1_title"], lang["tab2_title"], "ğŸ“š Search History" if st.session_state.language == "en" else "ğŸ“š æœç´¢å†å²"])
    
    with tab1:
        st.header(lang["tab1_title"])
        st.markdown("Please select filtering criteria, the system will: 1) Search Baidu News via SerpApi, 2) Format output with OpenAI" if st.session_state.language == "en" else "è¯·é€‰æ‹©ç­›é€‰æ¡ä»¶ï¼Œç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼Œ2ï¼‰ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º")
        st.markdown('<div style="font-size: 16px;">ğŸ’¡ Search Tip: You can choose keywords, companies, or both, combined with time range for flexible search</div>' if st.session_state.language == "en" else '<div style="font-size: 16px;">ğŸ’¡ æœç´¢æç¤ºï¼šæ‚¨å¯ä»¥é€‰æ‹©å…³é”®è¯ã€å…¬å¸æˆ–ä¸¤è€…éƒ½é€‰æ‹©ï¼Œé…åˆæ—¶é—´èŒƒå›´è¿›è¡Œçµæ´»æœç´¢</div>', unsafe_allow_html=True)
        
        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader(lang["keywords_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„é€‰é¡¹
            localized_options = get_localized_options()
            current_keywords = localized_options["keywords"]
            
            # é»˜è®¤é€‰æ‹©å‰5ä¸ªå…³é”®è¯
            default_keywords = current_keywords[:5] if len(current_keywords) >= 5 else current_keywords
            selected_keywords = st.multiselect(
                "Select keywords (multiple choice):" if st.session_state.language == "en" else "é€‰æ‹©å…³é”®è¯ï¼ˆå¯å¤šé€‰ï¼Œå¯é€‰ï¼‰:",
                options=current_keywords,
                default=default_keywords,
                help="Select critical minerals or related topics of interest, optional" if st.session_state.language == "en" else "é€‰æ‹©æ‚¨æ„Ÿå…´è¶£çš„å…³é”®çŸ¿äº§æˆ–ç›¸å…³ä¸»é¢˜ï¼Œå¯ä»¥ä¸é€‰æ‹©",
                format_func=lambda x: x  # å…³é”®ä¿®å¤ï¼šç¡®ä¿æ˜¾ç¤ºçš„æ˜¯æœ¬åœ°åŒ–å…³é”®è¯æ–‡æœ¬
            )
            
            # è‡ªå®šä¹‰å…³é”®è¯è¾“å…¥
            custom_keyword = st.text_input(
                "Input custom keyword:" if st.session_state.language == "en" else "è¾“å…¥è‡ªå®šä¹‰å…³é”®è¯:", 
                placeholder="Input other keywords..." if st.session_state.language == "en" else "è¾“å…¥å…¶ä»–å…³é”®è¯..."
            )
            if custom_keyword and custom_keyword not in selected_keywords:
                selected_keywords.append(custom_keyword)
        
        with col2:
            st.subheader(lang["companies_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„å…¬å¸é€‰é¡¹
            current_companies = localized_options["companies"]
            
            selected_companies = st.multiselect(
                "Select companies (multiple choice):" if st.session_state.language == "en" else "é€‰æ‹©å…¬å¸ï¼ˆå¯å¤šé€‰ï¼Œå¯é€‰ï¼‰:",
                options=current_companies,
                default=[],  # é»˜è®¤ä¸é€‰æ‹©ä»»ä½•å…¬å¸
                help="Select companies you are interested in, optional" if st.session_state.language == "en" else "é€‰æ‹©æ‚¨å…³æ³¨çš„å…¬å¸ï¼Œå¯ä»¥ä¸é€‰æ‹©",
                format_func=lambda x: x  # å…³é”®ä¿®å¤ï¼šç¡®ä¿æ˜¾ç¤ºçš„æ˜¯æœ¬åœ°åŒ–å…¬å¸åç§°
            )
            
            # æ˜¾ç¤ºé€‰ä¸­å…¬å¸
            if selected_companies:
                st.markdown(f"**{lang['selected_companies']}:**")
                for company in selected_companies:
                    if company in COMPANIES:
                        st.markdown(f"- {company}: {COMPANIES[company]}")
                    else:
                        st.markdown(f"- {company} (è‡ªå®šä¹‰)" if st.session_state.language == "zh" else f"- {company} (Custom)")
            
            # è‡ªå®šä¹‰å…¬å¸è¾“å…¥
            custom_company = st.text_input(
                "Input custom company name:" if st.session_state.language == "en" else "è¾“å…¥è‡ªå®šä¹‰å…¬å¸åç§°:", 
                placeholder="Input other company names..." if st.session_state.language == "en" else "è¾“å…¥å…¶ä»–å…¬å¸åç§°..."
            )
            if custom_company and custom_company not in selected_companies:
                selected_companies.append(custom_company)
        
        with col3:
            st.subheader(lang["time_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„æ—¶é—´é€‰é¡¹
            current_time_options = localized_options["time_options"]
            
            time_option = st.selectbox(
                "Select time range:" if st.session_state.language == "en" else "é€‰æ‹©æ—¶é—´èŒƒå›´:",
                options=list(current_time_options.keys()),
                index=0,
                format_func=lambda x: current_time_options[x]
            )
            
            # æ˜¾ç¤ºåŠ¨æ€æ—¶é—´èŒƒå›´
            current_date = datetime.now()
            if time_option == "2_weeks":
                start_date = current_date - timedelta(weeks=2)
                if st.session_state.language == "zh":
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Yå¹´%mæœˆ%dæ—¥")} è‡³ {current_date.strftime("%Yå¹´%mæœˆ%dæ—¥")}</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Y-%m-%d")} to {current_date.strftime("%Y-%m-%d")}</div>', unsafe_allow_html=True)
            elif time_option == "2_days":
                start_date = current_date - timedelta(days=2)
                if st.session_state.language == "zh":
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Yå¹´%mæœˆ%dæ—¥")} è‡³ {current_date.strftime("%Yå¹´%mæœˆ%dæ—¥")}</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Y-%m-%d")} to {current_date.strftime("%Y-%m-%d")}</div>', unsafe_allow_html=True)
            
            if time_option == "custom":
                col3a, col3b = st.columns(2)
                with col3a:
                    custom_start_date = st.date_input(lang["start_date"], value=datetime.now() - timedelta(days=7))
                with col3b:
                    custom_end_date = st.date_input(lang["end_date"], value=datetime.now())
            else:
                custom_start_date = None
                custom_end_date = None
        
        # åˆ†ææŒ‰é’®
        st.markdown("---")
        if st.button(lang["start_analysis"], type="primary", use_container_width=True):
            if not selected_keywords and not selected_companies:
                st.markdown(f'<div style="font-size: 16px; color: #ff4b4b;">{lang["error_no_keywords"] if not selected_keywords else lang["error_no_companies"]}</div>', unsafe_allow_html=True)
                st.markdown('<div style="font-size: 16px; color: #ffa500;">ğŸ’¡ Tip: Selecting only time range cannot perform effective search, please choose keywords or companies</div>' if st.session_state.language == "en" else '<div style="font-size: 16px; color: #ffa500;">ğŸ’¡ æç¤ºï¼šåªé€‰æ‹©æ—¶é—´èŒƒå›´æ— æ³•è¿›è¡Œæœ‰æ•ˆæœç´¢ï¼Œè¯·é€‰æ‹©å…³é”®è¯æˆ–å…¬å¸</div>', unsafe_allow_html=True)
            else:
                with st.spinner(lang["analyzing"]):
                    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ–°é—»æœç´¢Promptå¹¶è·å–æ–°é—»å†…å®¹
                    news_prompt = generate_news_prompt(
                        selected_keywords, 
                        selected_companies, 
                        time_option,  # ä¼ é€’é”®å€¼ï¼Œä¸æ˜¯æ˜¾ç¤ºæ–‡æœ¬
                        custom_start_date,
                        custom_end_date
                    )
                    
                    # æ˜¾ç¤ºç¬¬ä¸€æ­¥ç”Ÿæˆçš„Prompt
                    with st.expander(lang["generated_prompt"], expanded=False):
                        st.markdown(f'<div style="font-size: 18px;">{news_prompt}</div>', unsafe_allow_html=True)
                    
                    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
                    st.info("ğŸ” ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»..." if st.session_state.language == "zh" else "ğŸ” Step 1: Searching Baidu News with SerpApi...")
                    try:
                        news_results = search_baidu_news(selected_keywords, selected_companies, time_option, custom_start_date, custom_end_date)
                        
                        if news_results:
                            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º
                            st.info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šæ­£åœ¨ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º..." if st.session_state.language == "zh" else "ğŸ¤– Step 2: Formatting output with OpenAI...")
                            final_result = analyze_news_with_openai(news_results, selected_keywords, selected_companies)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{final_result}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_news_result = final_result
                            st.session_state.last_prompt = news_prompt
                            
                            # æ·»åŠ åˆ°å†å²è®°å½•
                            add_to_history(selected_keywords, selected_companies, time_option, final_result, news_prompt)
                        else:
                            # å¦‚æœæœªæ‰¾åˆ°æ–°é—»
                            error_msg = "âŒ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶æˆ–æ—¶é—´èŒƒå›´ã€‚" if st.session_state.language == "zh" else "âŒ No relevant news found, please try adjusting search conditions or time range."
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_news_result = error_msg
                            st.session_state.last_prompt = news_prompt
                        
                            # æ·»åŠ åˆ°å†å²è®°å½•
                            add_to_history(selected_keywords, selected_companies, time_option, error_msg, news_prompt)
                            
                    except Exception as e:
                        # å¦‚æœæœç´¢å¤±è´¥
                        error_msg = f"âŒ æœç´¢å¤±è´¥: {str(e)}"
                        st.subheader(lang["analysis_results"])
                        st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                        
                        # ä¿å­˜ç»“æœåˆ°session state
                        st.session_state.last_news_result = error_msg
                        st.session_state.last_prompt = news_prompt
                        
                        # æ·»åŠ åˆ°å†å²è®°å½•
                        add_to_history(selected_keywords, selected_companies, time_option, error_msg, news_prompt)
        
        # æ˜¾ç¤ºä¸Šæ¬¡åˆ†æç»“æœ
        if 'last_news_result' in st.session_state:
            st.markdown("---")
            st.subheader(lang["last_results"])
            with st.expander(lang["view_last_results"], expanded=False):
                st.markdown(f'<div style="font-size: 18px;">{st.session_state.last_news_result}</div>', unsafe_allow_html=True)
    
    with tab2:
        st.header(lang["tab2_title"])
        st.markdown("Input your custom prompt, the system will: 1) Search Baidu News via SerpApi, 2) Format output with OpenAI" if st.session_state.language == "en" else "è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰Promptï¼Œç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼Œ2ï¼‰ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º")
        
        # ç¤ºä¾‹Prompté€‰æ‹©
        st.subheader(lang["example_prompts"])
        example_prompts = [
            "Prepare a summary of top critical minerals news in China related to China Molybdenum / Luoyang Molybdenum Industry in the last week, or 2 days",
            "Latest news related to Company Name (i.e Tsingshan Holding group) mining investments in South America",
            "Chinese mining companies in South America lithium copper news last 24 hours",
            "Zijin Mining latest copper or lithium deals in South America",
            "CMOC (China Molybdenum) copper cobalt projects Peru Chile Brazil Argentina news",
            "Chinalco Toromocho mine Peru expansion investment protest",
            "China Minmetals South America, Africa mining copper lithium projects",
            "Ganfeng Lithium Argentina project production expansion news",
            "BYD Brazil Lithium Valley mining project developments",
            "Tianqi Lithium SQM Chile partnership lithium expansion",
            "CATL Bolivia Uyuni salt flats lithium plant progress",
            "CITIC Guoan Bolivia lithium plant project financing",
            "Summarize today's news on Chinese lithium companies in South America, focusing on deals, protests, and government policy.",
            "List new copper, cobalt, or lithium projects announced by Chinese mining companies in Argentina, Chile, Peru, Bolivia, and Brazil in the past 24 hours.",
            "Track latest stock or market for Chinese critical minerals companies with projects in South America, and Africa"
        ]
        
        selected_example = st.selectbox(
            "Select example prompt:" if st.session_state.language == "en" else "é€‰æ‹©ç¤ºä¾‹Prompt:",
            options=[lang["custom_input"]] + example_prompts,
            index=0
        )
        
        if selected_example == lang["custom_input"]:
            custom_prompt = st.text_area(
                lang["input_prompt"],
                placeholder=lang["prompt_placeholder"],
                height=150,
                help="Support Chinese and English input" if st.session_state.language == "en" else "æ”¯æŒä¸­è‹±æ–‡è¾“å…¥"
            )
        else:
            custom_prompt = st.text_area(
                lang["edit_selected_prompt"],
                value=selected_example,
                height=150
            )
        
        # æ¨¡å‹é€‰æ‹©
        model_option = st.selectbox(
            lang["model_selection"],
            options=["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            index=0,
            help="Select OpenAI model version" if st.session_state.language == "en" else "é€‰æ‹©OpenAIæ¨¡å‹ç‰ˆæœ¬"
        )
        
        # åˆ†ææŒ‰é’®
        if st.button(lang["analyze_button"], type="primary", use_container_width=True):
            if not custom_prompt.strip():
                st.markdown(f'<div style="font-size: 16px; color: #ff4b4b;">{lang["error_no_prompt"]}</div>', unsafe_allow_html=True)
            else:
                with st.spinner(lang["analyzing"]):
                    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
                    st.info("ğŸ” ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»..." if st.session_state.language == "zh" else "ğŸ” Step 1: Searching Baidu News with SerpApi...")
                    # ä»è‡ªå®šä¹‰promptä¸­æå–å…³é”®è¯å’Œå…¬å¸ä¿¡æ¯è¿›è¡Œæœç´¢
                    extracted_keywords, extracted_companies = extract_search_terms_from_prompt(custom_prompt)
                    
                    try:
                        news_results = search_baidu_news(extracted_keywords, extracted_companies, "2_weeks")
                        
                        if news_results:
                            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º
                            st.info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šæ­£åœ¨ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º..." if st.session_state.language == "zh" else "ğŸ¤– Step 2: Formatting output with OpenAI...")
                            final_result = analyze_news_with_openai(news_results, extracted_keywords, extracted_companies)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{final_result}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_custom_result = final_result
                            st.session_state.last_custom_prompt = custom_prompt
                        else:
                            # å¦‚æœæœªæ‰¾åˆ°æ–°é—»
                            error_msg = "âŒ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶æˆ–æ—¶é—´èŒƒå›´ã€‚" if st.session_state.language == "zh" else "âŒ No relevant news found, please try adjusting search conditions or time range."
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_custom_result = error_msg
                            st.session_state.last_custom_prompt = custom_prompt
                            
                    except Exception as e:
                        # å¦‚æœæœç´¢å¤±è´¥
                        error_msg = f"âŒ æœç´¢å¤±è´¥: {str(e)}"
                        st.subheader(lang["analysis_results"])
                        st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                        
                        # ä¿å­˜ç»“æœåˆ°session state
                        st.session_state.last_custom_result = error_msg
                        st.session_state.last_custom_prompt = custom_prompt
        
        # æ˜¾ç¤ºä¸Šæ¬¡åˆ†æç»“æœ
        if 'last_custom_result' in st.session_state:
            st.markdown("---")
            st.subheader(lang["last_results"])
            with st.expander(lang["view_last_results"], expanded=False):
                st.markdown(f'<div style="font-size: 18px;">{st.session_state.last_custom_result}</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºè¯­è¨€è½¬æ¢Promptï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'last_custom_language_prompt' in st.session_state:
                    with st.expander(lang["language_conversion_prompt"], expanded=False):
                        st.markdown(f'<div style="font-size: 16px;">{st.session_state.last_custom_language_prompt}</div>', unsafe_allow_html=True)
    
    with tab3:
        st.header("ğŸ“š Search History" if st.session_state.language == "en" else "ğŸ“š æœç´¢å†å²")
        
        if st.session_state.search_history:
            if 'selected_history_item' in st.session_state and st.session_state.selected_history_item:
                # æ˜¾ç¤ºé€‰ä¸­çš„å†å²è®°å½•è¯¦æƒ…
                history_item = st.session_state.selected_history_item
                
                # åŸºæœ¬ä¿¡æ¯
                st.subheader("ğŸ“‹ Historical Search Result Details" if st.session_state.language == "en" else "ğŸ“‹ Historical Search Result Details")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**{'æœç´¢æ—¶é—´' if st.session_state.language == 'zh' else 'Search Time'}:** {history_item['date']}")
                    st.markdown(f"**{'å…³é”®è¯' if st.session_state.language == 'zh' else 'Keywords'}:** {', '.join(history_item['keywords']) if history_item['keywords'] else ('æ— ' if st.session_state.language == 'zh' else 'None')}")
                with col2:
                    st.markdown(f"**{'å…¬å¸' if st.session_state.language == 'zh' else 'Companies'}:** {', '.join(history_item['companies']) if history_item['companies'] else ('æ— ' if st.session_state.language == 'zh' else 'None')}")
                    st.markdown(f"**{'æ—¶é—´èŒƒå›´' if st.session_state.language == 'zh' else 'Time Range'}:** {history_item['time_option']}")
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("---")
                st.subheader("ğŸ” æœç´¢ç»“æœ" if st.session_state.language == "zh" else "ğŸ” Search Results")
                st.markdown(f'<div style="font-size: 18px;">{history_item["result"]}</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºPrompt
                with st.expander("ğŸ“ ç”Ÿæˆçš„Prompt" if st.session_state.language == "zh" else "ğŸ“ Generated Prompt", expanded=False):
                    st.markdown(f'<div style="font-size: 16px;">{history_item["prompt"]}</div>', unsafe_allow_html=True)
            else:
                st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©ä¸€æ¡å†å²è®°å½•ä»¥æŸ¥çœ‹è¯¦æƒ…" if st.session_state.language == "zh" else "Please select a history record in the sidebar to view details")
        else:
            st.info("æš‚æ— æœç´¢å†å²" if st.session_state.language == "zh" else "No search history yet")

if __name__ == "__main__":
    main()
