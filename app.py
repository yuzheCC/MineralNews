import streamlit as st
import requests
import json
from datetime import datetime, timedelta
import pandas as pd
from openai import OpenAI
import re
from urllib.parse import urlparse
from serpapi import GoogleSearch
from bs4 import BeautifulSoup
import time

# ç®€å•çš„é“¾æ¥éªŒè¯å‡½æ•°
def validate_url(url):
    """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
    if not url or url.strip() == "":
        return False, "ç©ºé“¾æ¥"
    
    # æ£€æŸ¥URLæ ¼å¼
    try:
        parsed = urlparse(url)
        if not parsed.scheme or not parsed.netloc:
            return False, "æ— æ•ˆçš„URLæ ¼å¼"
    except:
        return False, "URLè§£æå¤±è´¥"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
    invalid_patterns = [
        r'example\.com',
        r'placeholder\.com',
        r'test\.com',
        r'sample\.com',
        r'news\.cnstock\.com.*202508',  # æ‚¨æåˆ°çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
        r'www\.cs\.com\.cn.*202508'     # æ‚¨æåˆ°çš„æ— æ•ˆé“¾æ¥æ¨¡å¼
    ]
    
    for pattern in invalid_patterns:
        if re.search(pattern, url, re.IGNORECASE):
            return False, "æ— æ•ˆé“¾æ¥æ¨¡å¼"
    
    return True, "é“¾æ¥æ ¼å¼æœ‰æ•ˆ"

def process_and_validate_result(result):
    """åå¤„ç†éªŒè¯APIè¿”å›ç»“æœä¸­çš„é“¾æ¥"""
    if not result or result.startswith("âŒ"):
        return result
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„è™šå‡é“¾æ¥æ¨¡å¼
    fake_patterns = [
        r'content_\d{6,}\.html?',  # content_123456.html
        r'/\d{10,}\.html?',        # /1234567890.html
        r'0{8,}',                  # è¿ç»­8ä¸ªæˆ–æ›´å¤šé›¶
        r'content_\d+\.htm',       # content_æ•°å­—.htm
        r'/202\d{1}/\d{8,}\.html', # /2025/12345678.html
    ]
    
    contains_fake_link = False
    for pattern in fake_patterns:
        if re.search(pattern, result):
            contains_fake_link = True
            break
    
    if contains_fake_link:
        # å¦‚æœæ£€æµ‹åˆ°è™šå‡é“¾æ¥ï¼Œæ›¿æ¢ä¸ºè­¦å‘Šä¿¡æ¯
        warning_msg = """
âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„è™šå‡é“¾æ¥ï¼Œç³»ç»Ÿæ— æ³•æä¾›çœŸå®å¯è®¿é—®çš„æ–°é—»é“¾æ¥ã€‚

å¯èƒ½çš„åŸå› ï¼š
1. è”ç½‘æœç´¢åŠŸèƒ½æœªæ­£å¸¸å·¥ä½œ
2. æœç´¢ç»“æœä¸­æ²¡æœ‰åŒ…å«æœ‰æ•ˆçš„æ–°é—»é“¾æ¥
3. å½“å‰æ—¶é—´èŒƒå›´å†…ç¼ºå°‘ç›¸å…³æ–°é—»

å»ºè®®ï¼š
- å°è¯•è°ƒæ•´å…³é”®è¯æˆ–æ—¶é—´èŒƒå›´
- ç¨åé‡è¯•æœç´¢
- è”ç³»æŠ€æœ¯æ”¯æŒæ£€æŸ¥è”ç½‘æœç´¢åŠŸèƒ½
        """
        
        if st.session_state.language == "en":
            warning_msg = """
âš ï¸ Detected potentially fake links. The system cannot provide real accessible news links.

Possible reasons:
1. Web search functionality not working properly
2. Search results contain no valid news links
3. Lack of relevant news in current time range

Suggestions:
- Try adjusting keywords or time range
- Retry search later
- Contact technical support to check web search functionality
            """
        
        return warning_msg
    
    return result

# å›½é™…åŒ–é…ç½®
LANGUAGES = {
    "en": {
        "title": "ğŸ” Critical Minerals News Analysis System",
        "tab1_title": "ğŸ“° News Filtering Analysis",
        "tab2_title": "ğŸ’¬ Custom Prompt",
        "keywords_title": "ğŸ”‘ Keyword Selection",
        "companies_title": "ğŸ¢ Company Selection", 
        "time_title": "â° Time Selection",
        "start_analysis": "ğŸš€ Start Analysis",
        "custom_prompt": "ğŸ’¬ Custom Prompt",
        "example_prompts": "ğŸ“š Example Prompts",
        "model_selection": "Model Selection",
        "analyze_button": "ğŸ” Start Analysis",
        "time_options": {
            "2_weeks": "Last 2 Weeks",
            "2_days": "Last 2 Days", 
            "custom": "Custom Time Range"
        },
        "start_date": "Start Date",
        "end_date": "End Date",
        "time_range_info": "ğŸ“… Time Range",
        "selected_companies": "Selected Companies",
        "news_analysis": "News Analysis",
        "generated_prompt": "Generated Prompt",
        "analysis_results": "Analysis Results",
        "last_results": "Last Analysis Results",
        "view_last_results": "View Last Results",
        "custom_input": "Custom Input",
        "edit_selected_prompt": "Edit Selected Prompt",
        "input_prompt": "Input Your Prompt",
        "prompt_placeholder": "Enter your prompt here...",
        "help_text": "Select DeepSeek model version",
        "error_no_keywords": "Please select at least one keyword!",
        "error_no_companies": "Please select at least one company!",
        "error_no_prompt": "Please enter prompt content!",
        "analyzing": "Analyzing with API...",
        "step1_analyzing": "ğŸ” Step 1: Analyzing custom prompt...",
        "step2_converting": "ğŸ”„ Step 2: Converting output language according to UI language setting...",
        "language_conversion_prompt": "ğŸ”„ Language Conversion Prompt",
        "api_key_expired": "âŒ API key expired, please update your DeepSeek API key",
        "api_quota_exceeded": "âŒ API quota exceeded, please check your account balance",
        "api_error": "âŒ API call error",
        "news_prompt_template": "Please help me find the LATEST and MOST RECENT news about the following keywords and companies in {time_range}:\n\nKeywords: {keywords}\nCompanies: {companies}\n\nCRITICAL TIME REQUIREMENTS:\n1. The time range '{time_range}' refers to the CURRENT DATE and time - NOT historical dates from previous years\n2. If the prompt mentions 'last 24 hours', 'last 2 weeks', etc., calculate this from TODAY'S DATE, not from 2024 or any other past year\n3. ONLY provide news that was published or occurred within the specified time range from TODAY\n4. If no recent news exists in the specified time range, clearly state 'No recent news found in {time_range} (calculated from current date)' instead of providing old information\n5. NEVER reference dates from 2024, 2023, or any previous years unless they are specifically relevant to current developments\n\nPlease provide:\n1. Title, source, and publication time for each news item\n2. Relevance score (0-1, 1 being most relevant) for each news item with selected keywords and companies\n3. Source Link: URL link to the original news article (must be real and accessible)\n4. News summary\n5. News complete content\n6. Sorted by relevance and recency\n\nPlease answer in English with clear formatting and ensure ALL news is from the specified time period calculated from TODAY'S DATE."
    },
    "zh": {
        "title": "ğŸ” å…³é”®çŸ¿äº§æ–°é—»åˆ†æç³»ç»Ÿ",
        "tab1_title": "ğŸ“° æ–°é—»ç­›é€‰åˆ†æ",
        "tab2_title": "ğŸ’¬ è‡ªå®šä¹‰Prompt",
        "keywords_title": "ğŸ”‘ å…³é”®è¯é€‰æ‹©",
        "companies_title": "ğŸ¢ å…¬å¸é€‰æ‹©",
        "time_title": "â° æ—¶é—´é€‰æ‹©", 
        "start_analysis": "ğŸš€ å¼€å§‹åˆ†æ",
        "custom_prompt": "ğŸ’¬ è‡ªå®šä¹‰Prompt",
        "example_prompts": "ğŸ“š ç¤ºä¾‹Prompt",
        "model_selection": "æ¨¡å‹é€‰æ‹©",
        "analyze_button": "ğŸ” å¼€å§‹åˆ†æ",
        "time_options": {
            "2_weeks": "æœ€è¿‘2å‘¨",
            "2_days": "æœ€è¿‘2å¤©",
            "custom": "è‡ªå®šä¹‰æ—¶é—´åŒºé—´"
        },
        "start_date": "å¼€å§‹æ—¥æœŸ",
        "end_date": "ç»“æŸæ—¥æœŸ",
        "time_range_info": "ğŸ“… æ—¶é—´èŒƒå›´",
        "selected_companies": "å·²é€‰å…¬å¸",
        "news_analysis": "æ–°é—»åˆ†æ",
        "generated_prompt": "ç”Ÿæˆçš„Prompt",
        "analysis_results": "åˆ†æç»“æœ",
        "last_results": "ä¸Šæ¬¡åˆ†æç»“æœ",
        "view_last_results": "æŸ¥çœ‹ä¸Šæ¬¡ç»“æœ",
        "custom_input": "è‡ªå®šä¹‰è¾“å…¥",
        "edit_selected_prompt": "ç¼–è¾‘é€‰ä¸­çš„Prompt",
        "input_prompt": "è¾“å…¥æ‚¨çš„Prompt",
        "prompt_placeholder": "è¯·è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„Prompt...",
        "help_text": "é€‰æ‹©DeepSeekæ¨¡å‹ç‰ˆæœ¬",
        "error_no_keywords": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå…³é”®è¯ï¼",
        "error_no_companies": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå…¬å¸ï¼",
        "error_no_prompt": "è¯·è¾“å…¥Promptå†…å®¹ï¼",
        "analyzing": "æ­£åœ¨è°ƒç”¨APIåˆ†æ...",
        "step1_analyzing": "ğŸ” ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨åˆ†æè‡ªå®šä¹‰Prompt...",
        "step2_converting": "ğŸ”„ ç¬¬äºŒæ­¥ï¼šæ­£åœ¨æ ¹æ®ç•Œé¢è¯­è¨€è¦æ±‚è½¬æ¢è¾“å‡ºè¯­è¨€...",
        "language_conversion_prompt": "ğŸ”„ è¯­è¨€è½¬æ¢Prompt",
        "api_key_expired": "âŒ APIå¯†é’¥å·²è¿‡æœŸï¼Œè¯·æ›´æ–°æ‚¨çš„DeepSeek APIå¯†é’¥",
        "api_quota_exceeded": "âŒ APIé…é¢å·²ç”¨å®Œï¼Œè¯·æ£€æŸ¥æ‚¨çš„è´¦æˆ·ä½™é¢",
        "api_error": "âŒ APIè°ƒç”¨é”™è¯¯",
        "news_prompt_template": "è¯·å¸®æˆ‘æŸ¥æ‰¾{time_range}å…³äºä»¥ä¸‹å…³é”®è¯å’Œå…¬å¸çš„æœ€æ–°æ–°é—»ï¼š\n\nå…³é”®è¯ï¼š{keywords}\nå…¬å¸ï¼š{companies}\n\nå…³é”®æ—¶é—´è¦æ±‚ï¼š\n1. æ—¶é—´èŒƒå›´'{time_range}'æŒ‡çš„æ˜¯å½“å‰æ—¥æœŸå’Œæ—¶é—´ - ä¸æ˜¯ä¹‹å‰å¹´ä»½çš„å†å²æ—¥æœŸ\n2. å¦‚æœæç¤ºä¸­æåˆ°'æœ€è¿‘24å°æ—¶'ã€'æœ€è¿‘2å‘¨'ç­‰ï¼Œè¯·ä»ä»Šå¤©çš„æ—¥æœŸå¼€å§‹è®¡ç®—ï¼Œè€Œä¸æ˜¯ä»2024å¹´æˆ–ä»»ä½•å…¶ä»–è¿‡å»çš„å¹´ä»½\n3. åªæä¾›åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…ï¼ˆä»ä»Šå¤©å¼€å§‹è®¡ç®—ï¼‰å‘å¸ƒæˆ–å‘ç”Ÿçš„æ–°é—»\n4. å¦‚æœåœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æœ€æ–°æ–°é—»ï¼Œè¯·æ˜ç¡®è¯´æ˜'åœ¨{time_range}å†…æœªæ‰¾åˆ°æœ€æ–°æ–°é—»ï¼ˆä»å½“å‰æ—¥æœŸè®¡ç®—ï¼‰'ï¼Œè€Œä¸æ˜¯æä¾›æ—§ä¿¡æ¯\n5. é™¤éä¸å½“å‰å‘å±•ç‰¹åˆ«ç›¸å…³ï¼Œå¦åˆ™æ°¸è¿œä¸è¦å¼•ç”¨2024å¹´ã€2023å¹´æˆ–ä»»ä½•ä¹‹å‰å¹´ä»½çš„æ—¥æœŸ\n\nè¯·æä¾›ï¼š\n1. æ¯æ¡æ–°é—»çš„æ ‡é¢˜ã€æ¥æºã€å‘å¸ƒæ—¶é—´\n2. æ¯æ¡æ–°é—»ä¸é€‰ä¸­å…³é”®è¯å’Œå…¬å¸çš„ç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1è¡¨ç¤ºæœ€ç›¸å…³ï¼‰\n3. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥ï¼ˆå¿…é¡»æ˜¯çœŸå®å¯è®¿é—®çš„é“¾æ¥ï¼‰\n4. æ–°é—»æ‘˜è¦\n5. æ–°é—»å®Œæ•´å†…å®¹\n6. æŒ‰ç›¸å…³æ€§å’Œæ—¶æ•ˆæ€§æ’åº\n\nè¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼è¦æ¸…æ™°æ˜“è¯»ï¼Œç¡®ä¿æ‰€æœ‰æ–°é—»éƒ½æ¥è‡ªä»å½“å‰æ—¥æœŸå¼€å§‹è®¡ç®—çš„æŒ‡å®šæ—¶é—´æ®µã€‚"
    }
}

# ä¸­è‹±æ–‡å…³é”®è¯æ˜ å°„
KEYWORDS_MAPPING = {
    "en": [
        "Lithium", "Cobalt", "Nickel", "Graphite", "Manganese", "Copper", "Aluminum", "Zinc", "Gallium", "Germanium", 
        "Rare Earth", "Tungsten", "Titanium", "Vanadium", "Antimony", "Beryllium", "Zirconium", "Tantalum", "Niobium",
        "Arsenic", "Barite", "Bismuth", "Cerium", "Cesium", "Chromium", "Dysprosium", "Erbium", "Europium", "Fluorite", 
        "Gadolinium", "Hafnium", "Holmium", "Indium", "Iridium", "Lanthanum", "Lutetium", "Magnesium", "Neodymium", 
        "Palladium", "Platinum", "Praseodymium", "Rhodium", "Rubidium", "Ruthenium", "Samarium", "Scandium", "Tellurium", 
        "Terbium", "Thulium", "Tin", "Ytterbium", "Yttrium", "China-US Critical Minerals", "Geopolitical Competition Critical Minerals",
        "China-Africa Critical Minerals", "EU-China-Africa Geopolitical Competition", "Belt and Road Initiative, China and Africa", 
        "Rare Earth US, China Rare Earth", "Rare Earth China-Africa", "EU-China-Africa Critical Minerals", 
        "Refining Africa and China Critical Minerals", "China-Congo Cobalt Industry"
    ],
    "zh": [
        "é”‚", "é’´", "é•", "çŸ³å¢¨", "é”°", "é“œ", "é“", "é”Œ", "é•“", "é”—", "ç¨€åœŸ", "é’¨", "é’›", "é’’", "é”‘", "é“", "é”†", "é’½", "é“Œ",
        "ç ·", "é‡æ™¶çŸ³", "é“‹", "é“ˆ", "é“¯", "é“¬", "é•", "é“’", "é“•", "è¤çŸ³", "é’†", "é“ª", "é’¬", "é“Ÿ", "é“±", "é•§", "é•¥", "é•", 
        "é’•", "é’¯", "é“‚", "é•¨", "é“‘", "é“·", "é’Œ", "é’", "é’ª", "ç¢²", "é“½", "é“¥", "é”¡", "é•±", "é’‡", "ä¸­ç¾å…³é”®çŸ¿äº§", "åœ°ç¼˜æ”¿æ²»ç«äº‰çš„å…³é”®çŸ¿äº§",
        "ä¸­éå…³é”®çŸ¿äº§", "æ¬§ç›Ÿã€ä¸­å›½ã€éæ´²åœ°ç¼˜æ”¿æ²»ç«äº‰", "ä¸€å¸¦ä¸€è·¯å€¡è®®,ä¸­å›½å’Œéæ´²", "ç¨€åœŸç¾å›½ï¼Œä¸­å›½ç¨€åœŸ", "ç¨€åœŸä¸­å›½-éæ´²ï¼Œç¨€åœŸä¸­é", 
        "æ¬§ç›Ÿ-ä¸­å›½-éæ´²å…³é”®çŸ¿äº§", "æç‚¼éæ´²å’Œä¸­å›½çš„å…³é”®çŸ¿äº§", "ä¸­å›½-åˆšæœé’´ä¸š"
    ]
}

# ä¸­è‹±æ–‡å…¬å¸æ˜ å°„
COMPANIES_MAPPING = {
    "en": {
        "CMOC China Molybdenum / Luoyang Molybdenum Industry": "Luoyang Molybdenum Group",
        "Zijin": "Zijin Mining Group Co., Ltd.",
        "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "Chengdu Chengxin Lithium Industry Co., Ltd.",
        "Tsingshan Holding group": "Tsingshan Holding Group Co., Ltd.",
        "Huayou Cobalt": "Zhejiang Huayou Cobalt Co., Ltd.",
        "Sinomine Resources Group": "Sinomine Resources Group Co., Ltd.",
        "Sinohydro Corporation": "Sinohydro Corporation",
        "Sichuan Yahua Industrial Group": "Sichuan Yahua Industrial Group Co., Ltd.",
        "Chinalco (Aluminum Corporation of China)": "Aluminum Corporation of China Limited",
        "China Minmetals Corporation": "China Minmetals Corporation",
        "China Hongqiao group": "China Hongqiao Group Limited",
        "China Non Metals Mining Group": "China Nonferrous Metal Mining Group Co., Ltd.",
        "Jiangxi Copper Company": "Jiangxi Copper Co., Ltd.",
        "Baiyin Nonferrous Group (BNMC)": "Baiyin Nonferrous Group Co., Ltd.",
        "Hunan Nonferrous Metals Group": "Hunan Nonferrous Metals Holding Group Co., Ltd.",
        "Tibet Huayu Mining": "Tibet Huayu Mining Co., Ltd.",
        "Ganfeng Lithium": "Ganfeng Lithium Co., Ltd.",
        "Tibet Everest Resources": "Tibet Summit Resources Co., Ltd.",
        "BYD": "BYD Co., Ltd.",
        "Tianqi Lithium": "Tianqi Lithium Corporation",
        "CATL": "Contemporary Amperex Technology Co., Limited"
    },
    "zh": {
        "CMOC China Molybdenum / Luoyang Molybdenum Industry": "æ´›é’¼é›†å›¢",
        "Zijin": "ç´«é‡‘çŸ¿ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
        "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "æˆéƒ½æˆé‘«é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
        "Tsingshan Holding group": "é’å±±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸",
        "Huayou Cobalt": "æµ™æ±Ÿåå‹é’´ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
        "Sinomine Resources Group": "ä¸­çŸ¿èµ„æºé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
        "Sinohydro Corporation": "ä¸­å›½æ°´åˆ©æ°´ç”µå»ºè®¾é›†å›¢å…¬å¸",
        "Sichuan Yahua Industrial Group": "å››å·é›…åŒ–å®ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (é›…åŒ–é›†å›¢)",
        "Chinalco (Aluminum Corporation of China)": "ä¸­å›½é“ä¸šé›†å›¢æœ‰é™å…¬å¸ (ä¸­å›½é“ä¸š / ä¸­é“)",
        "China Minmetals Corporation": "ä¸­å›½äº”çŸ¿é›†å›¢æœ‰é™å…¬å¸ (äº”çŸ¿é›†å›¢)",
        "China Hongqiao group": "ä¸­å›½å®æ¡¥é›†å›¢æœ‰é™å…¬å¸",
        "China Non Metals Mining Group": "ä¸­å›½æœ‰è‰²çŸ¿ä¸šé›†å›¢æœ‰é™å…¬å¸",
        "Jiangxi Copper Company": "æ±Ÿè¥¿é“œä¸šé›†å›¢æœ‰é™å…¬å¸ (æ±Ÿè¥¿é“œä¸š)",
        "Baiyin Nonferrous Group (BNMC)": "ç™½é“¶æœ‰è‰²é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (ç™½é“¶æœ‰è‰²)",
        "Hunan Nonferrous Metals Group": "æ¹–å—æœ‰è‰²é‡‘å±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸ (æ¹–å—æœ‰è‰²)",
        "Tibet Huayu Mining": "è¥¿è—åé’°çŸ¿ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (åé’°çŸ¿ä¸š)",
        "Ganfeng Lithium": "èµ£ä¸°é”‚ä¸š",
        "Tibet Everest Resources": "è¥¿è—ç å³°èµ„æºè‚¡ä»½æœ‰é™å…¬å¸",
        "BYD": "æ¯”äºšè¿ªè‚¡ä»½æœ‰é™å…¬å¸ (æ¯”äºšè¿ª)",
        "Tianqi Lithium": "å¤©é½é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (å¤©é½é”‚ä¸š)",
        "CATL": "å®å¾·æ—¶ä»£æ–°èƒ½æºç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ (å®å¾·æ—¶ä»£)"
    }
}

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="Critical Minerals News Analysis System",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è¯­è¨€é€‰æ‹©å™¨ï¼ˆé»˜è®¤è‹±æ–‡ï¼‰
if 'language' not in st.session_state:
    st.session_state.language = 'en'

# ä¾§è¾¹æ è¯­è¨€åˆ‡æ¢
with st.sidebar:
    st.header("ğŸŒ Language / è¯­è¨€")
    selected_language = st.selectbox(
        "Select Language / é€‰æ‹©è¯­è¨€",
        options=[("en", "English"), ("zh", "ä¸­æ–‡")],
        index=0 if st.session_state.language == 'en' else 1,
        format_func=lambda x: x[1]
    )
    
    if selected_language[0] != st.session_state.language:
        st.session_state.language = selected_language[0]
        st.rerun()
    
    # åˆå§‹åŒ–å†å²è®°å½•
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    
    # å†å²è®°å½•ç®¡ç†å‡½æ•°
    def add_to_history(keywords, companies, time_option, result, prompt):
        """æ·»åŠ æœç´¢ç»“æœåˆ°å†å²è®°å½•"""
        current_date = datetime.now()
        date_str = current_date.strftime('%Y-%m-%d %H:%M')
        
        # æ„å»ºæ ‡é¢˜
        keywords_str = ", ".join(keywords) if keywords else ("æ— å…³é”®è¯" if st.session_state.language == "zh" else "No Keywords")
        companies_str = ", ".join(companies) if companies else ("æ— å…¬å¸" if st.session_state.language == "zh" else "No Companies")
        
        if st.session_state.language == "zh":
            title = f"{date_str} - {keywords_str} - {companies_str}"
        else:
            title = f"{date_str} - {keywords_str} - {companies_str}"
        
        # åˆ›å»ºå†å²è®°å½•é¡¹
        history_item = {
            'id': len(st.session_state.search_history),
            'title': title,
            'date': date_str,
            'keywords': keywords,
            'companies': companies,
            'time_option': time_option,
            'result': result,
            'prompt': prompt,
            'language': st.session_state.language
        }
        
        # æ·»åŠ åˆ°å†å²è®°å½•å¼€å¤´
        st.session_state.search_history.insert(0, history_item)
        
        # ä¿æŒæœ€å¤š10æ¡è®°å½•
        if len(st.session_state.search_history) > 10:
            st.session_state.search_history = st.session_state.search_history[:10]
    

    
    # å†å²è®°å½•é€‰æ‹©å™¨
    st.markdown("---")
    st.subheader("ğŸ“š æœç´¢å†å²" if st.session_state.language == "zh" else "ğŸ“š Search History")
    
    if st.session_state.search_history:
        # åˆ›å»ºå†å²è®°å½•é€‰æ‹©å™¨
        history_titles = [item['title'] for item in st.session_state.search_history]
        selected_history = st.selectbox(
            "é€‰æ‹©å†å²è®°å½•" if st.session_state.language == "zh" else "Select History Record",
            options=history_titles,
            index=0
        )
        
        # ä¿å­˜é€‰ä¸­çš„å†å²è®°å½•åˆ°session state
        selected_item = next((item for item in st.session_state.search_history if item['title'] == selected_history), None)
        if selected_item:
            st.session_state.selected_history_item = selected_item
    else:
        st.info("æš‚æ— æœç´¢å†å²" if st.session_state.language == "zh" else "No search history yet")
        st.session_state.selected_history_item = None

# è·å–å½“å‰è¯­è¨€
lang = LANGUAGES[st.session_state.language]

# æ ¹æ®è¯­è¨€è·å–å…³é”®è¯å’Œå…¬å¸
KEYWORDS = KEYWORDS_MAPPING[st.session_state.language]
COMPANIES = COMPANIES_MAPPING[st.session_state.language]

TIME_OPTIONS = lang["time_options"]

# ç¡®ä¿å…³é”®è¯å’Œå…¬å¸åˆ—è¡¨æ ¹æ®è¯­è¨€åŠ¨æ€æ›´æ–°
def get_localized_options():
    """è·å–æœ¬åœ°åŒ–çš„é€‰é¡¹åˆ—è¡¨"""
    current_lang = st.session_state.language
    return {
        "keywords": KEYWORDS_MAPPING[current_lang],
        "companies": list(COMPANIES_MAPPING[current_lang].keys()),
        "time_options": LANGUAGES[current_lang]["time_options"]
    }

# API é…ç½® - ä» secrets.toml æ–‡ä»¶è¯»å–
try:
    SERPAPI_API_KEY = st.secrets["SERPAPI_API_KEY"]
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except KeyError as e:
    st.error(f"âŒ é…ç½®é”™è¯¯: åœ¨ .streamlit/secrets.toml æ–‡ä»¶ä¸­ç¼ºå°‘ API å¯†é’¥: {e}")
    st.stop()
except Exception as e:
    st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    st.stop()

# é¢„å®šä¹‰æ•°æ®
KEYWORDS = [
    "é”‚", "é’´", "é•", "çŸ³å¢¨", "é”°", "é“œ", "é“", "é”Œ", "é•“", "é”—", "ç¨€åœŸ", "é’¨", "é’›", "é’’", "é”‘", "é“", "é”†", "é’½", "é“Œ",
    "ç ·", "é‡æ™¶çŸ³", "é“‹", "é“ˆ", "é“¯", "é“¬", "é•", "é“’", "é“•", "è¤çŸ³", "é’†", "é“ª", "é’¬", "é“Ÿ", "é“±", "é•§", "é•¥", "é•", 
    "é’•", "é’¯", "é“‚", "é•¨", "é“‘", "é“·", "é’Œ", "é’", "é’ª", "ç¢²", "é“½", "é“¥", "é”¡", "é•±", "é’‡",     "ä¸­ç¾å…³é”®çŸ¿äº§", "åœ°ç¼˜æ”¿æ²»ç«äº‰çš„å…³é”®çŸ¿äº§",
    "ä¸­éå…³é”®çŸ¿äº§", "æ¬§ç›Ÿã€ä¸­å›½ã€éæ´²åœ°ç¼˜æ”¿æ²»ç«äº‰", "ä¸€å¸¦ä¸€è·¯å€¡è®®,ä¸­å›½å’Œéæ´²", "ç¨€åœŸç¾å›½ï¼Œä¸­å›½ç¨€åœŸ", "ç¨€åœŸä¸­å›½-éæ´²ï¼Œç¨€åœŸä¸­é", 
    "æ¬§ç›Ÿ-ä¸­å›½-éæ´²å…³é”®çŸ¿äº§", "æç‚¼éæ´²å’Œä¸­å›½çš„å…³é”®çŸ¿äº§", "ä¸­å›½-åˆšæœé’´ä¸š"
]

COMPANIES = {
    "CMOC China Molybdenum / Luoyang Molybdenum Industry": "æ´›é’¼é›†å›¢",
    "Zijin": "ç´«é‡‘çŸ¿ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
    "Chengxin Lithium (Chengxin Lithium Group / Chengxin)": "æˆéƒ½æˆé‘«é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
    "Tsingshan Holding group": "é’å±±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸",
    "Huayou Cobalt": "æµ™æ±Ÿåå‹é’´ä¸šè‚¡ä»½æœ‰é™å…¬å¸",
    "Sinomine Resources Group": "ä¸­çŸ¿èµ„æºé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸",
    "Sinohydro Corporation": "ä¸­å›½æ°´åˆ©æ°´ç”µå»ºè®¾é›†å›¢å…¬å¸",
    "Sichuan Yahua Industrial Group": "å››å·é›…åŒ–å®ä¸šé›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (é›…åŒ–é›†å›¢)",
    "Chinalco (Aluminum Corporation of China)": "ä¸­å›½é“ä¸šé›†å›¢æœ‰é™å…¬å¸ (ä¸­å›½é“ä¸š / ä¸­é“)",
    "China Minmetals Corporation": "ä¸­å›½äº”çŸ¿é›†å›¢æœ‰é™å…¬å¸ (äº”çŸ¿é›†å›¢)",
    "China Hongqiao group": "ä¸­å›½å®æ¡¥é›†å›¢æœ‰é™å…¬å¸",
    "China Non Metals Mining Group": "ä¸­å›½æœ‰è‰²çŸ¿ä¸šé›†å›¢æœ‰é™å…¬å¸",
    "Jiangxi Copper Company": "æ±Ÿè¥¿é“œä¸šé›†å›¢æœ‰é™å…¬å¸ (æ±Ÿè¥¿é“œä¸š)",
    "Baiyin Nonferrous Group (BNMC)": "ç™½é“¶æœ‰è‰²é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸ (ç™½é“¶æœ‰è‰²)",
    "Hunan Nonferrous Metals Group": "æ¹–å—æœ‰è‰²é‡‘å±æ§è‚¡é›†å›¢æœ‰é™å…¬å¸ (æ¹–å—æœ‰è‰²)",
    "Tibet Huayu Mining": "è¥¿è—åé’°çŸ¿ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (åé’°çŸ¿ä¸š)",
    "Ganfeng Lithium": "èµ£ä¸°é”‚ä¸š",
    "Tibet Everest Resources": "è¥¿è—ç å³°èµ„æºè‚¡ä»½æœ‰é™å…¬å¸",
    "BYD": "æ¯”äºšè¿ªè‚¡ä»½æœ‰é™å…¬å¸ (æ¯”äºšè¿ª)",
    "Tianqi Lithium": "å¤©é½é”‚ä¸šè‚¡ä»½æœ‰é™å…¬å¸ (å¤©é½é”‚ä¸š)",
    "CATL": "å®å¾·æ—¶ä»£æ–°èƒ½æºç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ (å®å¾·æ—¶ä»£)"
}

TIME_OPTIONS = {
    "æœ€è¿‘2å‘¨": "2_weeks",
    "æœ€è¿‘2å¤©": "2_days",
    "è‡ªå®šä¹‰æ—¶é—´åŒºé—´": "custom"
}

def generate_news_prompt(selected_keywords, selected_companies, time_option, custom_start_date=None, custom_end_date=None):
    """ç”Ÿæˆæœç´¢å‚æ•°æè¿°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰"""
    current_date = datetime.now()
    
    # æ„å»ºå…³é”®è¯æ˜¾ç¤º
    if selected_keywords:
        keywords_str = ", ".join(selected_keywords)
        keywords_display = f"Keywords: {keywords_str}" if st.session_state.language == "en" else f"å…³é”®è¯: {keywords_str}"
    else:
        keywords_display = "Keywords: Not specified" if st.session_state.language == "en" else "å…³é”®è¯: æœªæŒ‡å®š"
    
    # æ„å»ºå…¬å¸æ˜¾ç¤º
    if selected_companies:
        current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
        predefined_companies = [comp for comp in selected_companies if comp in current_companies_mapping]
        custom_companies = [comp for comp in selected_companies if comp not in current_companies_mapping]
        
        companies_parts = []
        if predefined_companies:
            companies_parts.append(f"Predefined companies: {', '.join(predefined_companies)}" if st.session_state.language == "en" else f"é¢„å®šä¹‰å…¬å¸: {', '.join(predefined_companies)}")
        if custom_companies:
            companies_parts.append(f"Custom companies: {', '.join(custom_companies)}" if st.session_state.language == "en" else f"è‡ªå®šä¹‰å…¬å¸: {', '.join(custom_companies)}")
        
        companies_display = "; ".join(companies_parts)
    else:
        companies_display = "Companies: Not specified" if st.session_state.language == "en" else "å…¬å¸: æœªæŒ‡å®š"
    
    # æ„å»ºæ—¶é—´å­—ç¬¦ä¸²
    if time_option == "2_weeks":
        start_date = current_date - timedelta(weeks=2)
        if st.session_state.language == "en":
            time_str = f"last 2 weeks ({start_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')})"
        else:
            time_str = f"æœ€è¿‘2å‘¨ï¼ˆ{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼‰"
    elif time_option == "2_days":
        start_date = current_date - timedelta(days=2)
        if st.session_state.language == "en":
            time_str = f"last 2 days ({start_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')})"
        else:
            time_str = f"æœ€è¿‘2å¤©ï¼ˆ{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼‰"
    elif time_option == "custom" and custom_start_date and custom_end_date:
        if st.session_state.language == "en":
            time_str = f"custom time range ({custom_start_date} to {custom_end_date})"
        else:
            time_str = f"è‡ªå®šä¹‰æ—¶é—´åŒºé—´ï¼ˆ{custom_start_date} è‡³ {custom_end_date}ï¼‰"
    else:
        time_str = "recent time period" if st.session_state.language == "en" else "æœ€è¿‘æ—¶é—´æ®µ"
    
    # æ„å»ºæœç´¢èŒƒå›´æè¿°
    if selected_keywords and selected_companies:
        search_scope = f"news about {keywords_display} or {companies_display}" if st.session_state.language == "en" else f"å…³äº{keywords_display}æˆ–{companies_display}çš„æ–°é—»"
    elif selected_keywords:
        search_scope = f"news about {keywords_display}" if st.session_state.language == "en" else f"å…³äº{keywords_display}çš„æ–°é—»"
    elif selected_companies:
        search_scope = f"news about {companies_display}" if st.session_state.language == "en" else f"å…³äº{companies_display}çš„æ–°é—»"
    else:
        search_scope = "news" if st.session_state.language == "en" else "æ–°é—»"
    
    # ç”Ÿæˆæœç´¢å‚æ•°æè¿°
    if st.session_state.language == "en":
        prompt = f"""Search Parameters:
- Search Scope: {search_scope}
- Time Range: {time_str}
- Current Date: {current_date.strftime('%Y-%m-%d')}
- Search Engine: Baidu News (via SerpApi) â†’ OpenAI Formatting
- Logic: OR (news content is relevant if it matches ANY keyword OR ANY company)

{keywords_display}
{companies_display}

The system will: 1) Search for real news articles via SerpApi, 2) Format output with OpenAI using the following 7 fields for each news item:
1. Title: Complete news title
2. Relevance: Relevance score (0-1, 1 being most relevant)
3. Source: News source (from Chinese media)
4. Source Link: URL link to the original news article (real and accessible)
5. Publish Time: Specific publication time (YYYY-MM-DD HH:MM)
6. Summary: Brief overview (100-200 words)
7. Full Text: Complete news content"""
    else:
        prompt = f"""æœç´¢å‚æ•°ï¼š
- æœç´¢èŒƒå›´ï¼š{search_scope}
- æ—¶é—´èŒƒå›´ï¼š{time_str}
- å½“å‰æ—¥æœŸï¼š{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}
- æœç´¢å¼•æ“ï¼šç™¾åº¦æ–°é—»ï¼ˆé€šè¿‡SerpApiï¼‰â†’ OpenAIæ ¼å¼åŒ–
- é€»è¾‘ï¼šæˆ–ï¼ˆæ–°é—»å†…å®¹ä¸ä»»ä¸€å…³é”®è¯æˆ–ä»»ä¸€å…¬å¸ç›¸å…³å³å¯ï¼‰

{keywords_display}
{companies_display}

ç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢çœŸå®æ–°é—»æ–‡ç« ï¼Œ2ï¼‰ä½¿ç”¨OpenAIæ ¼å¼åŒ–è¾“å‡ºï¼Œä¸ºæ¯æ¡æ–°é—»æä¾›ä»¥ä¸‹7ä¸ªå­—æ®µçš„åˆ†æï¼š
1. æ ‡é¢˜ï¼šæ–°é—»çš„å®Œæ•´æ ‡é¢˜
2. ç›¸å…³æ€§ï¼šç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1ä¸ºæœ€ç›¸å…³ï¼‰
3. æ¥æºï¼šæ–°é—»æ¥æºï¼ˆæ¥è‡ªä¸­å›½åª’ä½“ï¼‰
4. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥ï¼ˆçœŸå®å¯è®¿é—®ï¼‰
5. å‘å¸ƒæ—¶é—´ï¼šå…·ä½“å‘å¸ƒæ—¶é—´ï¼ˆå¹´-æœˆ-æ—¥ æ—¶:åˆ†ï¼‰
6. æ‘˜è¦ï¼šç®€è¦æ¦‚è¿°ï¼ˆ100-200å­—ï¼‰
7. å…¨æ–‡ï¼šæ–°é—»å®Œæ•´å†…å®¹"""
    
    return prompt

def generate_language_conversion_prompt(news_content, target_language):
    """ç”Ÿæˆè¯­è¨€è½¬æ¢Prompt - ç¬¬äºŒæ­¥ï¼šæ ¹æ®UIè¯­è¨€è¦æ±‚è½¬æ¢è¾“å‡ºè¯­è¨€"""
    if target_language == "en":
        prompt = f"""You are a professional news content translator and formatter. Please convert the following Chinese news analysis to English while maintaining the exact same structure and format.

âš ï¸ CRITICAL REQUIREMENTS:
- Convert ALL Chinese text to English
- Keep the exact same 7-field format: Title, Relevance, Source, Source Link, Publish Time, Summary, Full Text
- Maintain red bold formatting for field labels: <span style="color: #ff0000; font-weight: bold;">**Field Name**</span>
- Keep the same line breaks and spacing between fields
- Preserve all news content and relevance scores
- Ensure professional English translation

Original Chinese content:
{news_content}

Please provide the English version with the exact same format and structure."""
    else:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»å†…å®¹ç¿»è¯‘å’Œæ ¼å¼åŒ–ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»åˆ†æè½¬æ¢ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒå®Œå…¨ç›¸åŒçš„ç»“æ„å’Œæ ¼å¼ã€‚

âš ï¸ é‡è¦è¦æ±‚ï¼š
- å°†æ‰€æœ‰è‹±æ–‡æ–‡æœ¬è½¬æ¢ä¸ºä¸­æ–‡
- ä¿æŒå®Œå…¨ç›¸åŒçš„7å­—æ®µæ ¼å¼ï¼šæ ‡é¢˜ã€ç›¸å…³æ€§ã€æ¥æºã€æ¥æºé“¾æ¥ã€å‘å¸ƒæ—¶é—´ã€æ‘˜è¦ã€å…¨æ–‡
- ä¿æŒå­—æ®µæ ‡ç­¾çš„çº¢è‰²åŠ ç²—æ ¼å¼ï¼š<span style="color: #ff0000; font-weight: bold;">**å­—æ®µå**</span>
- ä¿æŒç›¸åŒçš„æ¢è¡Œå’Œå­—æ®µé—´é—´è·
- ä¿ç•™æ‰€æœ‰æ–°é—»å†…å®¹å’Œç›¸å…³æ€§è¯„åˆ†
- ç¡®ä¿ä¸“ä¸šçš„ä¸­æ–‡ç¿»è¯‘

åŸå§‹è‹±æ–‡å†…å®¹ï¼š
{news_content}

è¯·æä¾›ä¸­æ–‡ç‰ˆæœ¬ï¼Œä¿æŒå®Œå…¨ç›¸åŒçš„æ ¼å¼å’Œç»“æ„ã€‚"""
    
    return prompt

def search_baidu_news(keywords, companies, time_option, custom_start_date=None, custom_end_date=None):
    """ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼ˆç¬¬ä¸€æ­¥ï¼‰"""
    try:
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_terms = []
        
        # æ·»åŠ å…³é”®è¯
        if keywords:
            search_terms.extend(keywords)
        
        # æ·»åŠ å…¬å¸åç§°
        if companies:
            # è·å–å½“å‰è¯­è¨€çš„å…¬å¸æ˜ å°„
            current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
            for company in companies:
                if company in current_companies_mapping:
                    # ä½¿ç”¨é¢„å®šä¹‰å…¬å¸çš„ä¸­æ–‡åç§°è¿›è¡Œæœç´¢
                    search_terms.append(current_companies_mapping[company])
                else:
                    # ä½¿ç”¨è‡ªå®šä¹‰å…¬å¸åç§°
                    search_terms.append(company)
        
        # æ„å»ºæœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        query = " OR ".join(search_terms) if search_terms else "å…³é”®çŸ¿äº§"
        
        # æ·»åŠ æ—¶é—´èŒƒå›´é™åˆ¶
        current_date = datetime.now()
        if time_option == "2_weeks":
            start_date = current_date - timedelta(weeks=2)
            date_range = f" {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        elif time_option == "2_days":
            start_date = current_date - timedelta(days=2)
            date_range = f" {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        elif time_option == "custom" and custom_start_date and custom_end_date:
            date_range = f" {custom_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}..{custom_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        else:
            date_range = ""
        
        # æœ€ç»ˆæœç´¢æŸ¥è¯¢
        final_query = query + date_range
        
        # ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
        search = GoogleSearch({
            "engine": "baidu_news",
            "q": final_query,
            "api_key": SERPAPI_API_KEY,
            "medium":1,
            "rtt":4,
            "num": 8  # è·å–å‰8æ¡ç»“æœ
        })
        
        results = search.get_dict()
        
        # å¤„ç†æœç´¢ç»“æœ
        if "organic_results" in results and results["organic_results"]:
            return results["organic_results"]  # è¿”å›åŸå§‹æœç´¢ç»“æœ
        else:
            return None  # è¿”å›Noneè¡¨ç¤ºæœªæ‰¾åˆ°ç»“æœ
            
    except Exception as e:
        raise Exception(f"æœç´¢å¤±è´¥: {str(e)}")

def scrape_web_content(url, max_retries=3):
    """æŠ“å–ç½‘é¡µå†…å®¹"""
    try:
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        for attempt in range(max_retries):
            try:
                # å‘é€è¯·æ±‚
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()
                
                # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' not in content_type:
                    return f"âŒ æ— æ³•è·å–HTMLå†…å®¹ï¼Œå†…å®¹ç±»å‹: {content_type}"
                
                # è§£æHTML
                soup = BeautifulSoup(response.content, 'lxml')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
                for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    script.decompose()
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ¥æ‰¾åˆ°ä¸»è¦å†…å®¹
                content_selectors = [
                    'article',
                    '.article-content',
                    '.content',
                    '.news-content',
                    '.post-content',
                    '.entry-content',
                    'main',
                    '.main-content',
                    '#content',
                    '.article-body',
                    '.news-body'
                ]
                
                content_text = ""
                for selector in content_selectors:
                    elements = soup.select(selector)
                    if elements:
                        content_text = ' '.join([elem.get_text(strip=True) for elem in elements])
                        if len(content_text) > 100:  # ç¡®ä¿å†…å®¹è¶³å¤Ÿé•¿
                            break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå†…å®¹åŒºåŸŸï¼Œå°è¯•è·å–bodyå†…å®¹
                if not content_text or len(content_text) < 100:
                    body = soup.find('body')
                    if body:
                        content_text = body.get_text(strip=True)
                
                # æ¸…ç†æ–‡æœ¬
                if content_text:
                    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
                    content_text = re.sub(r'\s+', ' ', content_text)
                    # é™åˆ¶é•¿åº¦ï¼ˆé¿å…è¿‡é•¿çš„å†…å®¹ï¼‰
                    if len(content_text) > 5000:
                        content_text = content_text[:5000] + "..."
                    return content_text
                else:
                    return "âŒ æ— æ³•æå–ç½‘é¡µå†…å®¹"
                    
            except requests.exceptions.RequestException as e:
                if attempt < max_retries - 1:
                    time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                else:
                    return f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    return f"âŒ è§£æå¤±è´¥: {str(e)}"
                    
    except Exception as e:
        return f"âŒ æŠ“å–å¤±è´¥: {str(e)}"

def fix_html_rendering(content):
    """ä¿®å¤HTMLæ¸²æŸ“é—®é¢˜ï¼Œç¡®ä¿HTMLæ ‡ç­¾è¢«æ­£ç¡®æ˜¾ç¤º"""
    import html
    
    # å¦‚æœå†…å®¹è¢«HTMLè½¬ä¹‰äº†ï¼Œå…ˆè§£ç 
    if '&lt;' in content or '&gt;' in content or '&amp;' in content:
        content = html.unescape(content)
    
    # ç¡®ä¿spanæ ‡ç­¾æ ¼å¼æ­£ç¡®
    content = content.replace('&lt;span', '<span')
    content = content.replace('&lt;/span&gt;', '</span>')
    content = content.replace('&quot;', '"')
    
    return content

def normalize_publish_time(publish_time):
    """å°†å‘å¸ƒæ—¶é—´ç»Ÿä¸€è½¬æ¢ä¸º %Y-%m-%d æ ¼å¼"""
    if not publish_time:
        return None
    
    current_date = datetime.now()
    current_year = current_date.year
    
    # å¤„ç†"ä»Šå¤©"çš„æƒ…å†µ
    if "ä»Šå¤©" in publish_time:
        return current_date.strftime('%Y-%m-%d')
    
    # å¤„ç†"æ˜¨å¤©"çš„æƒ…å†µ
    elif "æ˜¨å¤©" in publish_time:
        return (current_date - timedelta(days=1)).strftime('%Y-%m-%d')
    
    # å¤„ç†"Xå¤©å‰"çš„æƒ…å†µ
    elif "å¤©å‰" in publish_time:
        try:
            days_ago = int(publish_time.replace("å¤©å‰", "").strip())
            target_date = current_date - timedelta(days=days_ago)
            return target_date.strftime('%Y-%m-%d')
        except ValueError:
            return None
    
    # å¤„ç†"XæœˆXæ—¥"æ ¼å¼ï¼ˆå¦‚ "9æœˆ27æ—¥"ï¼‰
    elif "æœˆ" in publish_time and "æ—¥" in publish_time:
        try:
            # æå–æœˆä»½å’Œæ—¥æœŸ
            parts = publish_time.replace("æœˆ", " ").replace("æ—¥", "").split()
            if len(parts) >= 2:
                month = int(parts[0])
                day = int(parts[1])
                
                # åˆ›å»ºæ—¥æœŸï¼Œå‡è®¾æ˜¯å½“å‰å¹´ä»½
                target_date = datetime(current_year, month, day)
                
                # å¦‚æœæ—¥æœŸåœ¨æœªæ¥ï¼ˆæ¯”å¦‚ç°åœ¨æ˜¯10æœˆï¼Œä½†æ—¥æœŸæ˜¯9æœˆï¼‰ï¼Œåˆ™è®¤ä¸ºæ˜¯å»å¹´
                if target_date > current_date:
                    target_date = datetime(current_year - 1, month, day)
                
                return target_date.strftime('%Y-%m-%d')
        except (ValueError, IndexError):
            return None
    
    # å¤„ç†æ ‡å‡†æ—¥æœŸæ ¼å¼ï¼ˆå¦‚ "2025-10-03 18:51"ï¼‰
    else:
        try:
            # å°è¯•è§£æ "YYYY-MM-DD HH:MM" æ ¼å¼
            news_date = datetime.strptime(publish_time.split()[0], '%Y-%m-%d')
            return news_date.strftime('%Y-%m-%d')
        except (ValueError, IndexError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ "YYYY-MM-DD" æ ¼å¼
            try:
                news_date = datetime.strptime(publish_time, '%Y-%m-%d')
                return news_date.strftime('%Y-%m-%d')
            except ValueError:
                return None

def analyze_news_with_openai(news_results, keywords, companies, start_date, end_date):
    """ä½¿ç”¨OpenAIåˆ†ææ–°é—»æœç´¢ç»“æœï¼Œé‡æ–°æ ¹æ®æ—¶é—´èŒƒå›´è¿›è¡Œç­›é€‰å¤„ç†"""
    
    # å°† start_date å’Œ end_date è½¬æ¢ä¸º date å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
    if isinstance(start_date, datetime):
        start_date_obj = start_date.date()
    else:
        start_date_obj = start_date
    
    if isinstance(end_date, datetime):
        end_date_obj = end_date.date()
    else:
        end_date_obj = end_date
    
    # Filter news_results by Publish Time
    filtered_news = []
    
    for news_item in news_results:
        publish_time = news_item.get('date', '')
        
        # è§„èŒƒåŒ–å‘å¸ƒæ—¶é—´æ ¼å¼
        standardized_date = normalize_publish_time(publish_time)
        
        if standardized_date:
            try:
                news_date = datetime.strptime(standardized_date, '%Y-%m-%d').date()
                
                # ä½¿ç”¨ date å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
                if start_date_obj <= news_date <= end_date_obj:
                    filtered_news.append(news_item)
            except ValueError:
                continue  # Skip if date cannot be parsed

    # Check if any news collected after filtering
    if not filtered_news:
        return ("æœªæ‰¾åˆ°ç¬¦åˆæ—¶é—´èŒƒå›´çš„æ–°é—»" if st.session_state.language == "zh" else "No news found within the time range")

    # Proceed to analyze with OpenAI
    try:
        # The rest of the code remains the same, analysis continues...
        enhanced_news_results = []
        for i, news_item in enumerate(filtered_news):
            enhanced_item = news_item.copy()
            news_url = news_item.get('link', '')
            if news_url and validate_url(news_url)[0]:
                if st.session_state.language == "zh":
                    progress_text = f"ğŸ” æ­£åœ¨æŠ“å–ç¬¬{i+1}æ¡æ–°é—»å†…å®¹..."
                else:
                    progress_text = f"ğŸ” Scraping content for news item {i+1}..."
                if hasattr(st, 'info'):
                    st.info(progress_text)

                full_text = scrape_web_content(news_url)
                enhanced_item['full_text'] = full_text
            else:
                enhanced_item['full_text'] = "âŒ æ— æ•ˆé“¾æ¥æˆ–æ— æ³•è®¿é—®"
            enhanced_news_results.append(enhanced_item)

        # Rebuild the prompt for language-specific analysis
        current_lang = st.session_state.language if hasattr(st, 'session_state') and 'language' in st.session_state else "zh"
        
        if current_lang == "zh":
            analysis_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ç™¾åº¦æ–°é—»æœç´¢ç»“æœï¼Œä¸ºæ¯æ¡æ–°é—»æä¾›è¯¦ç»†çš„åˆ†æå’Œæ ¼å¼åŒ–è¾“å‡ºã€‚

é‡è¦è¯´æ˜ï¼š
1. è¯·ç¡®ä¿æ‰€æœ‰è¾“å‡ºå†…å®¹éƒ½æ˜¯ä¸­æ–‡ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€å…¨æ–‡ç­‰æ‰€æœ‰å­—æ®µ
2. è¯·ç›´æ¥è¾“å‡ºHTMLæ ¼å¼ï¼Œä¸è¦è½¬ä¹‰HTMLæ ‡ç­¾
3. ä½¿ç”¨ä»¥ä¸‹HTMLæ ¼å¼æ¥æ ‡è®°å­—æ®µæ ‡é¢˜ï¼š<span style="color: #ff0000; font-weight: bold;">**å­—æ®µå**</span>

æœç´¢å…³é”®è¯ï¼š{', '.join(keywords) if keywords else 'æ— '}
æœç´¢å…¬å¸ï¼š{', '.join(companies) if companies else 'æ— '}

è¯·ä¸ºæ¯æ¡æ–°é—»æä¾›ä»¥ä¸‹7ä¸ªå­—æ®µçš„è¯¦ç»†åˆ†æï¼š

1. æ ‡é¢˜ï¼šæ–°é—»çš„å®Œæ•´æ ‡é¢˜ï¼ˆä¿æŒåŸæ ‡é¢˜ï¼Œå¦‚æœæ˜¯è‹±æ–‡æ ‡é¢˜åˆ™ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰
2. ç›¸å…³æ€§ï¼šç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-1ï¼Œ1ä¸ºæœ€ç›¸å…³ï¼‰ï¼ŒåŸºäºä¸å…³é”®è¯å’Œå…¬å¸çš„åŒ¹é…åº¦
3. æ¥æºï¼šæ–°é—»æ¥æºï¼ˆå¿…é¡»æ¥è‡ªä¸­å›½åª’ä½“ï¼‰
4. æ¥æºé“¾æ¥ï¼šåŸå§‹æ–°é—»æ–‡ç« çš„URLé“¾æ¥
5. å‘å¸ƒæ—¶é—´ï¼šå…·ä½“å‘å¸ƒæ—¶é—´ï¼ˆå¹´-æœˆ-æ—¥ æ—¶:åˆ†ï¼‰
6. æ‘˜è¦ï¼šæ–°é—»çš„ç®€è¦æ¦‚è¿°ï¼ˆ100-200å­—ï¼Œå¿…é¡»ç”¨ä¸­æ–‡ï¼‰
7. å…¨æ–‡ï¼šæ–°é—»çš„å®Œæ•´å†…å®¹ï¼ˆå¦‚æœæŠ“å–æˆåŠŸï¼Œè¯·å°†æŠ“å–åˆ°çš„å†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼›å¦‚æœæŠ“å–å¤±è´¥ï¼Œè¯·åŸºäºæ ‡é¢˜å’Œæ‘˜è¦ç”Ÿæˆåˆç†çš„ä¸­æ–‡å†…å®¹ï¼‰

æ–°é—»æœç´¢ç»“æœï¼ˆåŒ…å«æŠ“å–çš„å®Œæ•´å†…å®¹ï¼‰ï¼š
{json.dumps(enhanced_news_results, ensure_ascii=False, indent=2)}

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
<span style="color: #ff0000; font-weight: bold;">**æ ‡é¢˜**</span>: [æ–°é—»æ ‡é¢˜]

<span style="color: #ff0000; font-weight: bold;">**ç›¸å…³æ€§**</span>: [0-1åˆ†å€¼]

<span style="color: #ff0000; font-weight: bold;">**æ¥æº**</span>: [æ–°é—»æ¥æº]

<span style="color: #ff0000; font-weight: bold;">**æ¥æºé“¾æ¥**</span>: [URLé“¾æ¥]

<span style="color: #ff0000; font-weight: bold;">**å‘å¸ƒæ—¶é—´**</span>: [æ—¶é—´]

<span style="color: #ff0000; font-weight: bold;">**æ‘˜è¦**</span>: [æ‘˜è¦å†…å®¹]

<span style="color: #ff0000; font-weight: bold;">**å…¨æ–‡**</span>: [å…¨æ–‡å†…å®¹]

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦è½¬ä¹‰HTMLæ ‡ç­¾ã€‚"""
        else:
            analysis_prompt = f"""You are a professional news analyst. Please analyze the following Baidu news search results and provide detailed analysis for each news item.

IMPORTANT Instructions:
1. Please ensure ALL output content is in English, including titles, summaries, full text, and all other fields
2. Please output HTML format directly, do NOT escape HTML tags
3. Use this HTML format for field headers: <span style="color: #ff0000; font-weight: bold;">**Field Name**</span>

Search Keywords: {', '.join(keywords) if keywords else 'None'}
Search Companies: {', '.join(companies) if companies else 'None'}

Please provide detailed analysis for each news item with the following 7 fields:

1. Title: Complete news title (translate Chinese titles to English if necessary)
2. Relevance: Relevance score (0-1, 1 being most relevant), based on match with keywords and companies
3. Source: News source (must be from Chinese media, keep original Chinese name)
4. Source Link: URL link to the original news article
5. Publish Time: Specific publication time (YYYY-MM-DD HH:MM)
6. Summary: Brief overview (100-200 words, must be in English)
7. Full Text: Complete news content (if scraping successful, translate the scraped content to English; if scraping failed, generate reasonable English content based on title and snippet)

News search results (with scraped full content):
{json.dumps(enhanced_news_results, ensure_ascii=False, indent=2)}

Output format example:
<span style="color: #ff0000; font-weight: bold;">**Title**</span>: [News title]

<span style="color: #ff0000; font-weight: bold;">**Relevance**</span>: [0-1 score]

<span style="color: #ff0000; font-weight: bold;">**Source**</span>: [News source]

<span style="color: #ff0000; font-weight: bold;">**Source Link**</span>: [URL link]

<span style="color: #ff0000; font-weight: bold;">**Publish Time**</span>: [Time]

<span style="color: #ff0000; font-weight: bold;">**Summary**</span>: [Summary content]

<span style="color: #ff0000; font-weight: bold;">**Full Text**</span>: [Full text content]

---

Please strictly follow the above format and do NOT escape HTML tags."""
        
        # è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ
        analysis_result = call_openai_api(analysis_prompt)
        
        # ä¿®å¤HTMLæ¸²æŸ“é—®é¢˜
        analysis_result = fix_html_rendering(analysis_result)
        
        return analysis_result
    except Exception as e:
        return format_news_results(news_results, keywords, companies)

def format_news_results(news_results, keywords, companies):
    """æ ¼å¼åŒ–æ–°é—»æœç´¢ç»“æœ"""
    formatted_results = []
    
    # è·å–å½“å‰è¯­è¨€è®¾ç½®
    current_lang = st.session_state.language if hasattr(st, 'session_state') and hasattr(st.session_state, 'language') else "zh"
    
    for i, news in enumerate(news_results[:5]):  # é™åˆ¶æ˜¾ç¤ºå‰5æ¡æ–°é—»
        # è®¡ç®—ç›¸å…³æ€§è¯„åˆ†
        relevance_score = calculate_relevance_score(news, keywords, companies)
        
        # æ ¹æ®è¯­è¨€è®¾ç½®æ ¼å¼åŒ–å•æ¡æ–°é—»
        if current_lang == "zh":
            news_item = f"""<span style="color: #ff0000; font-weight: bold;">**Titleï¼ˆæ ‡é¢˜ï¼‰**</span>: {news.get('title', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Relevanceï¼ˆç›¸å…³æ€§ï¼‰**</span>: {relevance_score:.2f}

<span style="color: #ff0000; font-weight: bold;">**Sourceï¼ˆæ¥æºï¼‰**</span>: {news.get('source', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Source Linkï¼ˆæ¥æºé“¾æ¥ï¼‰**</span>: {news.get('link', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Publish Timeï¼ˆå‘å¸ƒæ—¶é—´ï¼‰**</span>: {news.get('date', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Summaryï¼ˆæ‘˜è¦ï¼‰**</span>: {news.get('snippet', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Full Textï¼ˆå…¨æ–‡ï¼‰**</span>: {news.get('snippet', 'N/A')}

---
"""
        else:
            news_item = f"""<span style="color: #ff0000; font-weight: bold;">**Title**</span>: {news.get('title', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Relevance**</span>: {relevance_score:.2f}

<span style="color: #ff0000; font-weight: bold;">**Source**</span>: {news.get('source', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Source Link**</span>: {news.get('link', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Publish Time**</span>: {news.get('date', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Summary**</span>: {news.get('snippet', 'N/A')}

<span style="color: #ff0000; font-weight: bold;">**Full Text**</span>: {news.get('snippet', 'N/A')}

---
"""
        formatted_results.append(news_item)
    
    return "\n".join(formatted_results)

def calculate_relevance_score(news, keywords, companies):
    """è®¡ç®—æ–°é—»ç›¸å…³æ€§è¯„åˆ†"""
    score = 0.0
    title = news.get('title', '').lower()
    snippet = news.get('snippet', '').lower()
    content = f"{title} {snippet}"
    
    # å…³é”®è¯åŒ¹é…
    if keywords:
        keyword_matches = sum(1 for keyword in keywords if keyword.lower() in content)
        score += (keyword_matches / len(keywords)) * 0.6
    
    # å…¬å¸åŒ¹é…
    if companies:
        company_matches = 0
        current_companies_mapping = COMPANIES_MAPPING[st.session_state.language]
        for company in companies:
            if company in current_companies_mapping:
                company_name = current_companies_mapping[company].lower()
                if company_name in content:
                    company_matches += 1
            else:
                if company.lower() in content:
                    company_matches += 1
        score += (company_matches / len(companies)) * 0.4
    
    # ç¡®ä¿è¯„åˆ†åœ¨0-1ä¹‹é—´
    return min(max(score, 0.1), 1.0)

def extract_search_terms_from_prompt(prompt):
    """ä»è‡ªå®šä¹‰promptä¸­æå–å…³é”®è¯å’Œå…¬å¸ä¿¡æ¯"""
    keywords = []
    companies = []
    
    # è·å–å½“å‰è¯­è¨€çš„å…³é”®è¯å’Œå…¬å¸åˆ—è¡¨
    current_keywords = KEYWORDS_MAPPING[st.session_state.language]
    current_companies = list(COMPANIES_MAPPING[st.session_state.language].keys())
    
    prompt_lower = prompt.lower()
    
    # æå–å…³é”®è¯
    for keyword in current_keywords:
        if keyword.lower() in prompt_lower:
            keywords.append(keyword)
    
    # æå–å…¬å¸
    for company in current_companies:
        if company.lower() in prompt_lower:
            companies.append(company)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„å®šä¹‰çš„å…³é”®è¯æˆ–å…¬å¸ï¼Œä½¿ç”¨ä¸€äº›é€šç”¨å…³é”®è¯
    if not keywords and not companies:
        keywords = ["å…³é”®çŸ¿äº§", "çŸ¿ä¸š"] if st.session_state.language == "zh" else ["critical minerals", "mining"]
    
    return keywords, companies

def extract_keywords_and_time_with_chatgpt(prompt, model="gpt-4o"):
    """ä½¿ç”¨ChatGPTä»è‡ªå®šä¹‰promptä¸­æå–æ ¸å¿ƒå…³é”®è¯å’Œæ—¶é—´ä¿¡æ¯"""
    try:
        # æ„å»ºæå–prompt
        if st.session_state.language == "zh":
            extraction_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„promptä¸­æå–æ ¸å¿ƒæœç´¢å…³é”®è¯å’Œæ—¶é—´ä¿¡æ¯ã€‚

ç”¨æˆ·è¾“å…¥çš„prompt: "{prompt}"

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "keywords": ["æ ¸å¿ƒå…³é”®è¯"],
    "time_description": "æ—¶é—´æè¿°",
    "time_type": "relative|absolute|none",
    "time_value": "å…·ä½“æ—¶é—´å€¼",
    "explanation": "æå–è¿‡ç¨‹çš„ç®€è¦è¯´æ˜"
}}

æå–è§„åˆ™ï¼š
1. keywords: åªæå–æœ€æ ¸å¿ƒçš„1-2ä¸ªå…³é”®è¯ï¼Œå¿…é¡»æ˜¯å…³é”®çŸ¿äº§ã€çŸ¿ä¸šã€å…¬å¸ã€æŠ•èµ„ã€é¡¹ç›®ç­‰ç›¸å…³çš„æ ¸å¿ƒè¯æ±‡
   - ä¾‹å¦‚ï¼š"I searched for Chinese top news on critical minerals in the last 2 days" åªæå– "critical minerals"
   - ä¾‹å¦‚ï¼š"Latest news about Zijin Mining lithium projects" åªæå– "Zijin Mining" å’Œ "lithium"
   - ä¸è¦æå–"news"ã€"latest"ã€"top"ã€"Chinese"ç­‰ä¿®é¥°è¯
2. time_description: åŸå§‹promptä¸­çš„æ—¶é—´æè¿°ï¼ˆå¦‚"æœ€è¿‘2å¤©"ã€"last 2 days"ç­‰ï¼‰
3. time_type: "relative"è¡¨ç¤ºç›¸å¯¹æ—¶é—´ï¼Œ"absolute"è¡¨ç¤ºç»å¯¹æ—¶é—´ï¼Œ"none"è¡¨ç¤ºæ— æ—¶é—´é™åˆ¶
4. time_value: å¦‚æœæ˜¯ç›¸å¯¹æ—¶é—´ï¼Œæå–æ•°å­—å’Œå•ä½ï¼ˆå¦‚"2 days"ã€"1 week"ç­‰ï¼‰
5. explanation: ç®€è¦è¯´æ˜æå–çš„æ ¸å¿ƒå…³é”®è¯å’Œæ—¶é—´ä¿¡æ¯

è¯·ç¡®ä¿ï¼š
- åªæå–æœ€æ ¸å¿ƒçš„å…³é”®è¯ï¼Œæ•°é‡æ§åˆ¶åœ¨1-2ä¸ª
- å…³é”®è¯è¦å…·ä½“ä¸”ç›¸å…³ï¼Œä¸è¦åŒ…å«ä¿®é¥°è¯
- æ—¶é—´ä¿¡æ¯è¦å‡†ç¡®
- JSONæ ¼å¼è¦æ­£ç¡®
- å¦‚æœpromptä¸­æ²¡æœ‰æ˜ç¡®çš„æ—¶é—´ä¿¡æ¯ï¼Œtime_typeè®¾ä¸º"none"
"""
        else:
            extraction_prompt = f"""You are a professional text analysis assistant. Please extract core search keywords and time information from the following user prompt.

User prompt: "{prompt}"

Please return the result in the following JSON format:
{{
    "keywords": ["core keyword"],
    "time_description": "time description",
    "time_type": "relative|absolute|none",
    "time_value": "specific time value",
    "explanation": "brief explanation of extraction process"
}}

Extraction rules:
1. keywords: Extract only the most core 1-2 keywords related to critical minerals, mining, companies, investments, projects, etc.
   - Example: "I searched for Chinese top news on critical minerals in the last 2 days" â†’ extract only "critical minerals"
   - Example: "Latest news about Zijin Mining lithium projects" â†’ extract only "Zijin Mining" and "lithium"
   - Do NOT extract modifiers like "news", "latest", "top", "Chinese", etc.
2. time_description: Original time description in the prompt (e.g., "last 2 days", "recent week", etc.)
3. time_type: "relative" for relative time, "absolute" for absolute time, "none" for no time limit
4. time_value: If relative time, extract number and unit (e.g., "2 days", "1 week", etc.)
5. explanation: Brief explanation of extracted core keywords and time information

Please ensure:
- Extract only the most core keywords, limit to 1-2 keywords
- Keywords should be specific and relevant, exclude modifiers
- Time information is accurate
- JSON format is correct
- If no clear time information in prompt, set time_type to "none"
"""
        
        # è°ƒç”¨OpenAI API
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": extraction_prompt}
            ],
            temperature=0.1,
            max_tokens=1000,
            stream=False
        )
        
        response_text = completion.choices[0].message.content
        
        # è§£æJSONå“åº”
        import json
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_str = response_text[json_start:json_end]
                result = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                if all(key in result for key in ['keywords', 'time_description', 'time_type', 'time_value', 'explanation']):
                    return result
                else:
                    raise ValueError("Missing required fields in JSON response")
            else:
                raise ValueError("No valid JSON found in response")
                
        except (json.JSONDecodeError, ValueError) as e:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            return {
                "keywords": ["å…³é”®çŸ¿äº§", "çŸ¿ä¸š"] if st.session_state.language == "zh" else ["critical minerals", "mining"],
                "time_description": "æ— æ—¶é—´é™åˆ¶" if st.session_state.language == "zh" else "no time limit",
                "time_type": "none",
                "time_value": "",
                "explanation": f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯: {str(e)}"
            }
            
    except Exception as e:
        # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return {
            "keywords": ["å…³é”®çŸ¿äº§", "çŸ¿ä¸š"] if st.session_state.language == "zh" else ["critical minerals", "mining"],
            "time_description": "æ— æ—¶é—´é™åˆ¶" if st.session_state.language == "zh" else "no time limit",
            "time_type": "none",
            "time_value": "",
            "explanation": f"APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯: {str(e)}"
        }

def convert_time_to_date_range(time_description, time_type, time_value):
    """å°†æ—¶é—´æè¿°è½¬æ¢ä¸ºå…·ä½“çš„æ—¥æœŸèŒƒå›´"""
    try:
        current_date = datetime.now()
        
        if time_type == "none" or not time_value:
            # é»˜è®¤ä½¿ç”¨æœ€è¿‘6ä¸ªæœˆ
            start_date = current_date - timedelta(days=180)  # çº¦6ä¸ªæœˆ
            end_date = current_date
            return start_date, end_date, "æœ€è¿‘6ä¸ªæœˆ" if st.session_state.language == "zh" else "last 6 months"
        
        elif time_type == "relative":
            # å¤„ç†ç›¸å¯¹æ—¶é—´
            time_value_lower = time_value.lower().strip()
            
            # å¤„ç†å¤©æ•°
            if "day" in time_value_lower:
                try:
                    days = int(''.join(filter(str.isdigit, time_value_lower)))
                    start_date = current_date - timedelta(days=days)
                    end_date = current_date
                    time_desc = f"æœ€è¿‘{days}å¤©" if st.session_state.language == "zh" else f"last {days} days"
                    return start_date, end_date, time_desc
                except ValueError:
                    pass
            
            # å¤„ç†å‘¨æ•°
            elif "week" in time_value_lower:
                try:
                    weeks = int(''.join(filter(str.isdigit, time_value_lower)))
                    start_date = current_date - timedelta(weeks=weeks)
                    end_date = current_date
                    time_desc = f"æœ€è¿‘{weeks}å‘¨" if st.session_state.language == "zh" else f"last {weeks} weeks"
                    return start_date, end_date, time_desc
                except ValueError:
                    pass
            
            # å¤„ç†æœˆæ•°
            elif "month" in time_value_lower:
                try:
                    months = int(''.join(filter(str.isdigit, time_value_lower)))
                    start_date = current_date - timedelta(days=months * 30)  # è¿‘ä¼¼å¤„ç†
                    end_date = current_date
                    time_desc = f"æœ€è¿‘{months}ä¸ªæœˆ" if st.session_state.language == "zh" else f"last {months} months"
                    return start_date, end_date, time_desc
                except ValueError:
                    pass
            
            # å¤„ç†å°æ—¶
            elif "hour" in time_value_lower:
                try:
                    hours = int(''.join(filter(str.isdigit, time_value_lower)))
                    start_date = current_date - timedelta(hours=hours)
                    end_date = current_date
                    time_desc = f"æœ€è¿‘{hours}å°æ—¶" if st.session_state.language == "zh" else f"last {hours} hours"
                    return start_date, end_date, time_desc
                except ValueError:
                    pass
        
        # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨é»˜è®¤å€¼
        start_date = current_date - timedelta(days=180)  # çº¦6ä¸ªæœˆ
        end_date = current_date
        return start_date, end_date, "æœ€è¿‘6ä¸ªæœˆ" if st.session_state.language == "zh" else "last 6 months"
        
    except Exception as e:
        # å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨é»˜è®¤å€¼
        current_date = datetime.now()
        start_date = current_date - timedelta(days=180)  # çº¦6ä¸ªæœˆ
        end_date = current_date
        return start_date, end_date, "æœ€è¿‘6ä¸ªæœˆ" if st.session_state.language == "zh" else "last 6 months"

def translate_keywords_to_chinese(keywords, model="gpt-4o"):
    """å°†è‹±æ–‡å…³é”®å­—ç¿»è¯‘æˆä¸­æ–‡"""
    try:
        if not keywords:
            return []
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡å­—ç¬¦
        has_english = any(any(c.isalpha() and ord(c) < 128 for c in keyword) for keyword in keywords)
        if not has_english:
            # å¦‚æœæ²¡æœ‰è‹±æ–‡å­—ç¬¦ï¼Œç›´æ¥è¿”å›åŸå…³é”®å­—
            return keywords
        
        # æ„å»ºç¿»è¯‘prompt
        keywords_str = ", ".join(keywords)
        translation_prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡å…³é”®è¯ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§ï¼š

è‹±æ–‡å…³é”®è¯: {keywords_str}

ç¿»è¯‘è¦æ±‚ï¼š
1. ä¿æŒå…³é”®è¯çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
2. å¦‚æœæ˜¯çŸ¿ä¸šã€çŸ¿äº§ç›¸å…³çš„ä¸“ä¸šæœ¯è¯­ï¼Œè¯·ä½¿ç”¨æ ‡å‡†çš„ä¸­æ–‡ç¿»è¯‘
3. å¦‚æœæ˜¯å…¬å¸åç§°ï¼Œè¯·ä½¿ç”¨è¯¥å…¬å¸çš„å®˜æ–¹ä¸­æ–‡åç§°
4. åªè¿”å›ç¿»è¯‘åçš„ä¸­æ–‡å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”
5. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–å†…å®¹

è¯·ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœï¼š"""
        
        # è°ƒç”¨OpenAI APIè¿›è¡Œç¿»è¯‘
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": translation_prompt}
            ],
            temperature=0.1,
            max_tokens=500,
            stream=False
        )
        
        response_text = completion.choices[0].message.content.strip()
        
        # è§£æç¿»è¯‘ç»“æœ
        translated_keywords = [keyword.strip() for keyword in response_text.split(',') if keyword.strip()]
        
        # å¦‚æœç¿»è¯‘å¤±è´¥æˆ–ç»“æœä¸ºç©ºï¼Œè¿”å›åŸå…³é”®å­—
        if not translated_keywords:
            return keywords
        
        return translated_keywords
        
    except Exception as e:
        # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œè¿”å›åŸå…³é”®å­—
        print(f"Translation failed: {str(e)}")
        return keywords

def call_openai_api(prompt, model="gpt-4o"):
    """è°ƒç”¨OpenAI API (ç”¨äºè¯­è¨€è½¬æ¢å’Œå†…å®¹åˆ†æ)"""
    try:
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=OPENAI_API_KEY,
        )
        
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=4096,
            stream=False
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "unauthorized" in error_msg.lower():
            return "âŒ APIè°ƒç”¨å¤±è´¥: æ‚¨çš„OpenAI APIå¯†é’¥å·²è¿‡æœŸæˆ–æ— æ•ˆï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®ã€‚"
        elif "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
            return "âŒ APIè°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°OpenAI APIè°ƒç”¨é…é¢é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ã€‚"
        else:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}"

def main():
    st.title(lang["title"])
    st.markdown("---")
    
    # åˆ›å»ºä¸‰ä¸ªTabé¡µ
    tab1, tab2, tab3 = st.tabs([lang["tab1_title"], lang["tab2_title"], "ğŸ“š Search History" if st.session_state.language == "en" else "ğŸ“š æœç´¢å†å²"])
    
    with tab1:
        st.header(lang["tab1_title"])
        st.markdown("Please select filtering criteria, the system will: 1) Search Baidu News via SerpApi, 2) Format output with OpenAI" if st.session_state.language == "en" else "è¯·é€‰æ‹©ç­›é€‰æ¡ä»¶ï¼Œç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼Œ2ï¼‰ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º")
        st.markdown('<div style="font-size: 16px;">ğŸ’¡ Search Tip: You can choose keywords, companies, or both, combined with time range for flexible search</div>' if st.session_state.language == "en" else '<div style="font-size: 16px;">ğŸ’¡ æœç´¢æç¤ºï¼šæ‚¨å¯ä»¥é€‰æ‹©å…³é”®è¯ã€å…¬å¸æˆ–ä¸¤è€…éƒ½é€‰æ‹©ï¼Œé…åˆæ—¶é—´èŒƒå›´è¿›è¡Œçµæ´»æœç´¢</div>', unsafe_allow_html=True)
        
        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader(lang["keywords_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„é€‰é¡¹
            localized_options = get_localized_options()
            current_keywords = localized_options["keywords"]
            
            # é»˜è®¤é€‰æ‹©å‰5ä¸ªå…³é”®è¯
            default_keywords = current_keywords[:5] if len(current_keywords) >= 5 else current_keywords
            selected_keywords = st.multiselect(
                "Select keywords (multiple choice):" if st.session_state.language == "en" else "é€‰æ‹©å…³é”®è¯ï¼ˆå¯å¤šé€‰ï¼Œå¯é€‰ï¼‰:",
                options=current_keywords,
                default=default_keywords,
                help="Select critical minerals or related topics of interest, optional" if st.session_state.language == "en" else "é€‰æ‹©æ‚¨æ„Ÿå…´è¶£çš„å…³é”®çŸ¿äº§æˆ–ç›¸å…³ä¸»é¢˜ï¼Œå¯ä»¥ä¸é€‰æ‹©",
                format_func=lambda x: x  # å…³é”®ä¿®å¤ï¼šç¡®ä¿æ˜¾ç¤ºçš„æ˜¯æœ¬åœ°åŒ–å…³é”®è¯æ–‡æœ¬
            )
            
            # è‡ªå®šä¹‰å…³é”®è¯è¾“å…¥
            custom_keyword = st.text_input(
                "Input custom keyword:" if st.session_state.language == "en" else "è¾“å…¥è‡ªå®šä¹‰å…³é”®è¯:", 
                placeholder="Input other keywords..." if st.session_state.language == "en" else "è¾“å…¥å…¶ä»–å…³é”®è¯..."
            )
            if custom_keyword and custom_keyword not in selected_keywords:
                selected_keywords.append(custom_keyword)
        
        with col2:
            st.subheader(lang["companies_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„å…¬å¸é€‰é¡¹
            current_companies = localized_options["companies"]
            
            selected_companies = st.multiselect(
                "Select companies (multiple choice):" if st.session_state.language == "en" else "é€‰æ‹©å…¬å¸ï¼ˆå¯å¤šé€‰ï¼Œå¯é€‰ï¼‰:",
                options=current_companies,
                default=[],  # é»˜è®¤ä¸é€‰æ‹©ä»»ä½•å…¬å¸
                help="Select companies you are interested in, optional" if st.session_state.language == "en" else "é€‰æ‹©æ‚¨å…³æ³¨çš„å…¬å¸ï¼Œå¯ä»¥ä¸é€‰æ‹©",
                format_func=lambda x: x  # å…³é”®ä¿®å¤ï¼šç¡®ä¿æ˜¾ç¤ºçš„æ˜¯æœ¬åœ°åŒ–å…¬å¸åç§°
            )
            
            # æ˜¾ç¤ºé€‰ä¸­å…¬å¸
            if selected_companies:
                st.markdown(f"**{lang['selected_companies']}:**")
                for company in selected_companies:
                    if company in COMPANIES:
                        st.markdown(f"- {company}: {COMPANIES[company]}")
                    else:
                        st.markdown(f"- {company} (è‡ªå®šä¹‰)" if st.session_state.language == "zh" else f"- {company} (Custom)")
            
            # è‡ªå®šä¹‰å…¬å¸è¾“å…¥
            custom_company = st.text_input(
                "Input custom company name:" if st.session_state.language == "en" else "è¾“å…¥è‡ªå®šä¹‰å…¬å¸åç§°:", 
                placeholder="Input other company names..." if st.session_state.language == "en" else "è¾“å…¥å…¶ä»–å…¬å¸åç§°..."
            )
            if custom_company and custom_company not in selected_companies:
                selected_companies.append(custom_company)
        
        with col3:
            st.subheader(lang["time_title"])
            # åŠ¨æ€è·å–å½“å‰è¯­è¨€çš„æ—¶é—´é€‰é¡¹
            current_time_options = localized_options["time_options"]
            
            time_option = st.selectbox(
                "Select time range:" if st.session_state.language == "en" else "é€‰æ‹©æ—¶é—´èŒƒå›´:",
                options=list(current_time_options.keys()),
                index=0,
                format_func=lambda x: current_time_options[x]
            )
            
            # æ˜¾ç¤ºåŠ¨æ€æ—¶é—´èŒƒå›´
            current_date = datetime.now()
            if time_option == "2_weeks":
                start_date = current_date - timedelta(weeks=2)
                if st.session_state.language == "zh":
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Yå¹´%mæœˆ%dæ—¥")} è‡³ {current_date.strftime("%Yå¹´%mæœˆ%dæ—¥")}</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Y-%m-%d")} to {current_date.strftime("%Y-%m-%d")}</div>', unsafe_allow_html=True)
            elif time_option == "2_days":
                start_date = current_date - timedelta(days=2)
                if st.session_state.language == "zh":
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Yå¹´%mæœˆ%dæ—¥")} è‡³ {current_date.strftime("%Yå¹´%mæœˆ%dæ—¥")}</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div style="font-size: 16px;">{lang["time_range_info"]}: {start_date.strftime("%Y-%m-%d")} to {current_date.strftime("%Y-%m-%d")}</div>', unsafe_allow_html=True)
            
            if time_option == "custom":
                col3a, col3b = st.columns(2)
                with col3a:
                    custom_start_date = st.date_input(lang["start_date"], value=datetime.now() - timedelta(days=7))
                with col3b:
                    custom_end_date = st.date_input(lang["end_date"], value=datetime.now())
            else:
                custom_start_date = None
                custom_end_date = None
        
        # åˆ†ææŒ‰é’®
        st.markdown("---")
        if st.button(lang["start_analysis"], type="primary", use_container_width=True):
            if not selected_keywords and not selected_companies:
                st.markdown(f'<div style="font-size: 16px; color: #ff4b4b;">{lang["error_no_keywords"] if not selected_keywords else lang["error_no_companies"]}</div>', unsafe_allow_html=True)
                st.markdown('<div style="font-size: 16px; color: #ffa500;">ğŸ’¡ Tip: Selecting only time range cannot perform effective search, please choose keywords or companies</div>' if st.session_state.language == "en" else '<div style="font-size: 16px; color: #ffa500;">ğŸ’¡ æç¤ºï¼šåªé€‰æ‹©æ—¶é—´èŒƒå›´æ— æ³•è¿›è¡Œæœ‰æ•ˆæœç´¢ï¼Œè¯·é€‰æ‹©å…³é”®è¯æˆ–å…¬å¸</div>', unsafe_allow_html=True)
            else:
                with st.spinner(lang["analyzing"]):
                    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ–°é—»æœç´¢Promptå¹¶è·å–æ–°é—»å†…å®¹
                    news_prompt = generate_news_prompt(
                        selected_keywords, 
                        selected_companies, 
                        time_option,  # ä¼ é€’é”®å€¼ï¼Œä¸æ˜¯æ˜¾ç¤ºæ–‡æœ¬
                        custom_start_date,
                        custom_end_date
                    )
                    
                    # æ˜¾ç¤ºç¬¬ä¸€æ­¥ç”Ÿæˆçš„Prompt
                    with st.expander(lang["generated_prompt"], expanded=False):
                        st.markdown(f'<div style="font-size: 18px;">{news_prompt}</div>', unsafe_allow_html=True)
                    
                    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
                    st.info("ğŸ” ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»..." if st.session_state.language == "zh" else "ğŸ” Step 1: Searching Baidu News with SerpApi...")
                    try:
                        news_results = search_baidu_news(selected_keywords, selected_companies, time_option, custom_start_date, custom_end_date)
                        
                        if news_results:
                            # è®¡ç®—å®é™…çš„æ—¶é—´èŒƒå›´ç”¨äºè¿‡æ»¤
                            current_date = datetime.now()
                            if time_option == "2_weeks":
                                filter_start_date = current_date - timedelta(weeks=2)
                                filter_end_date = current_date
                            elif time_option == "2_days":
                                filter_start_date = current_date - timedelta(days=2)
                                filter_end_date = current_date
                            elif time_option == "custom" and custom_start_date and custom_end_date:
                                filter_start_date = datetime.combine(custom_start_date, datetime.min.time())
                                filter_end_date = datetime.combine(custom_end_date, datetime.max.time())
                            else:
                                # é»˜è®¤ä½¿ç”¨æœ€è¿‘2å‘¨
                                filter_start_date = current_date - timedelta(weeks=2)
                                filter_end_date = current_date
                            
                            # æ˜¾ç¤ºæ—¶é—´èŒƒå›´ä¿¡æ¯
                            if st.session_state.language == "zh":
                                st.info(f"ğŸ“… è¿‡æ»¤æ—¶é—´èŒƒå›´: {filter_start_date.strftime('%Y-%m-%d')} è‡³ {filter_end_date.strftime('%Y-%m-%d')}")
                            else:
                                st.info(f"ğŸ“… Filter time range: {filter_start_date.strftime('%Y-%m-%d')} to {filter_end_date.strftime('%Y-%m-%d')}")
                            
                            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º
                            st.info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šæ­£åœ¨ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º..." if st.session_state.language == "zh" else "ğŸ¤– Step 2: Formatting output with OpenAI...")
                            final_result = analyze_news_with_openai(news_results, selected_keywords, selected_companies, filter_start_date, filter_end_date)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{final_result}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_news_result = final_result
                            st.session_state.last_prompt = news_prompt
                            
                            # æ·»åŠ åˆ°å†å²è®°å½•
                            add_to_history(selected_keywords, selected_companies, time_option, final_result, news_prompt)
                        else:
                            # å¦‚æœæœªæ‰¾åˆ°æ–°é—»
                            error_msg = "âŒ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶æˆ–æ—¶é—´èŒƒå›´ã€‚" if st.session_state.language == "zh" else "âŒ No relevant news found, please try adjusting search conditions or time range."
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_news_result = error_msg
                            st.session_state.last_prompt = news_prompt
                        
                            # æ·»åŠ åˆ°å†å²è®°å½•
                            add_to_history(selected_keywords, selected_companies, time_option, error_msg, news_prompt)
                            
                    except Exception as e:
                        # å¦‚æœæœç´¢å¤±è´¥
                        error_msg = f"âŒ æœç´¢å¤±è´¥: {str(e)}"
                        st.subheader(lang["analysis_results"])
                        st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                        
                        # ä¿å­˜ç»“æœåˆ°session state
                        st.session_state.last_news_result = error_msg
                        st.session_state.last_prompt = news_prompt
                        
                        # æ·»åŠ åˆ°å†å²è®°å½•
                        add_to_history(selected_keywords, selected_companies, time_option, error_msg, news_prompt)
        
        # æ˜¾ç¤ºä¸Šæ¬¡åˆ†æç»“æœ
        if 'last_news_result' in st.session_state:
            st.markdown("---")
            st.subheader(lang["last_results"])
            with st.expander(lang["view_last_results"], expanded=False):
                st.markdown(f'<div style="font-size: 18px;">{st.session_state.last_news_result}</div>', unsafe_allow_html=True)
    
    with tab2:
        st.header(lang["tab2_title"])
        st.markdown("Input your custom prompt, the system will: 1) Search Baidu News via SerpApi, 2) Format output with OpenAI" if st.session_state.language == "en" else "è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰Promptï¼Œç³»ç»Ÿå°†ï¼š1ï¼‰é€šè¿‡SerpApiæœç´¢ç™¾åº¦æ–°é—»ï¼Œ2ï¼‰ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º")
        
        # ç¤ºä¾‹Prompté€‰æ‹©
        st.subheader(lang["example_prompts"])
        example_prompts = [
            "Prepare a summary of top critical minerals news in China related to China Molybdenum / Luoyang Molybdenum Industry in the last week, or 2 days",
            "Latest news related to Company Name (i.e Tsingshan Holding group) mining investments in South America",
            "Chinese mining companies in South America lithium copper news last 24 hours",
            "Zijin Mining latest copper or lithium deals in South America",
            "CMOC (China Molybdenum) copper cobalt projects Peru Chile Brazil Argentina news",
            "Chinalco Toromocho mine Peru expansion investment protest",
            "China Minmetals South America, Africa mining copper lithium projects",
            "Ganfeng Lithium Argentina project production expansion news",
            "BYD Brazil Lithium Valley mining project developments",
            "Tianqi Lithium SQM Chile partnership lithium expansion",
            "CATL Bolivia Uyuni salt flats lithium plant progress",
            "CITIC Guoan Bolivia lithium plant project financing",
            "Summarize today's news on Chinese lithium companies in South America, focusing on deals, protests, and government policy.",
            "List new copper, cobalt, or lithium projects announced by Chinese mining companies in Argentina, Chile, Peru, Bolivia, and Brazil in the past 24 hours.",
            "Track latest stock or market for Chinese critical minerals companies with projects in South America, and Africa"
        ]
        
        selected_example = st.selectbox(
            "Select example prompt:" if st.session_state.language == "en" else "é€‰æ‹©ç¤ºä¾‹Prompt:",
            options=[lang["custom_input"]] + example_prompts,
            index=0
        )
        
        if selected_example == lang["custom_input"]:
            custom_prompt = st.text_area(
                lang["input_prompt"],
                placeholder=lang["prompt_placeholder"],
                height=150,
                help="Support Chinese and English input" if st.session_state.language == "en" else "æ”¯æŒä¸­è‹±æ–‡è¾“å…¥"
            )
        else:
            custom_prompt = st.text_area(
                lang["edit_selected_prompt"],
                value=selected_example,
                height=150
            )
        
        # æ¨¡å‹é€‰æ‹©
        model_option = st.selectbox(
            lang["model_selection"],
            options=["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            index=0,
            help="Select OpenAI model version" if st.session_state.language == "en" else "é€‰æ‹©OpenAIæ¨¡å‹ç‰ˆæœ¬"
        )
        
        # åˆ†ææŒ‰é’®
        if st.button(lang["analyze_button"], type="primary", use_container_width=True):
            if not custom_prompt.strip():
                st.markdown(f'<div style="font-size: 16px; color: #ff4b4b;">{lang["error_no_prompt"]}</div>', unsafe_allow_html=True)
            else:
                with st.spinner(lang["analyzing"]):
                    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ChatGPTæå–å…³é”®è¯å’Œæ—¶é—´ä¿¡æ¯
                    st.info("ğŸ§  ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨ä½¿ç”¨ChatGPTåˆ†æPrompt..." if st.session_state.language == "zh" else "ğŸ§  Step 1: Analyzing prompt with ChatGPT...")
                    
                    try:
                        # ä½¿ç”¨ChatGPTæå–å…³é”®è¯å’Œæ—¶é—´ä¿¡æ¯
                        extraction_result = extract_keywords_and_time_with_chatgpt(custom_prompt, model_option)
                        
                        # æ˜¾ç¤ºæå–ç»“æœ
                        st.success("âœ… Promptåˆ†æå®Œæˆï¼" if st.session_state.language == "zh" else "âœ… Prompt analysis completed!")
                        
                        # ç¬¬ä¸‰æ­¥ï¼šç¿»è¯‘å…³é”®å­—ä¸ºä¸­æ–‡
                        st.info("ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šæ­£åœ¨ç¿»è¯‘å…³é”®å­—ä¸ºä¸­æ–‡..." if st.session_state.language == "zh" else "ğŸ”„ Step 3: Translating keywords to Chinese...")
                        
                        # ç¿»è¯‘å…³é”®å­—
                        original_keywords = extraction_result["keywords"]
                        translated_keywords = translate_keywords_to_chinese(original_keywords, model_option)
                        
                        # æ˜¾ç¤ºç¿»è¯‘ç»“æœ
                        st.success("âœ… å…³é”®å­—ç¿»è¯‘å®Œæˆï¼" if st.session_state.language == "zh" else "âœ… Keywords translation completed!")
                        
                        # åˆ›å»ºä¸‰åˆ—æ˜¾ç¤ºæå–çš„å‚æ•°
                        col_extract1, col_extract2, col_extract3 = st.columns(3)
                        
                        with col_extract1:
                            st.markdown("**ğŸ”‘ åŸå§‹å…³é”®è¯ / Original Keywords:**")
                            original_display = ", ".join(original_keywords) if original_keywords else ("æ— " if st.session_state.language == "zh" else "None")
                            st.markdown(f'<div style="background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 5px 0;">{original_display}</div>', unsafe_allow_html=True)
                        
                        with col_extract2:
                            st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡å…³é”®è¯ / Chinese Keywords:**")
                            translated_display = ", ".join(translated_keywords) if translated_keywords else ("æ— " if st.session_state.language == "zh" else "None")
                            st.markdown(f'<div style="background-color: #e8f5e8; padding: 10px; border-radius: 5px; margin: 5px 0;">{translated_display}</div>', unsafe_allow_html=True)
                        
                        with col_extract3:
                            st.markdown("**â° æ—¶é—´èŒƒå›´ / Time Range:**")
                            time_display = extraction_result["time_description"] if extraction_result["time_description"] else ("æ— æ—¶é—´é™åˆ¶" if st.session_state.language == "zh" else "No time limit")
                            st.markdown(f'<div style="background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 5px 0;">{time_display}</div>', unsafe_allow_html=True)
                        
                        # æ˜¾ç¤ºæå–è¯´æ˜
                        with st.expander("ğŸ“ æå–è¯´æ˜ / Extraction Explanation", expanded=False):
                            st.markdown(f'<div style="font-size: 14px;">{extraction_result["explanation"]}</div>', unsafe_allow_html=True)
                        
                        # ç¬¬å››æ­¥ï¼šè½¬æ¢æ—¶é—´ä¸ºå…·ä½“æ—¥æœŸèŒƒå›´
                        st.info("ğŸ“… ç¬¬å››æ­¥ï¼šæ­£åœ¨è½¬æ¢æ—¶é—´èŒƒå›´..." if st.session_state.language == "zh" else "ğŸ“… Step 4: Converting time range...")
                        
                        filter_start_date, filter_end_date, time_desc = convert_time_to_date_range(
                            extraction_result["time_description"],
                            extraction_result["time_type"],
                            extraction_result["time_value"]
                        )
                        
                        # æ˜¾ç¤ºå…·ä½“çš„æ—¶é—´èŒƒå›´
                        st.success(f"ğŸ“… æœç´¢æ—¶é—´èŒƒå›´: {filter_start_date.strftime('%Y-%m-%d')} è‡³ {filter_end_date.strftime('%Y-%m-%d')}" if st.session_state.language == "zh" else f"ğŸ“… Search time range: {filter_start_date.strftime('%Y-%m-%d')} to {filter_end_date.strftime('%Y-%m-%d')}")
                        
                        # ç¬¬äº”æ­¥ï¼šä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»
                        st.info("ğŸ” ç¬¬äº”æ­¥ï¼šæ­£åœ¨ä½¿ç”¨SerpApiæœç´¢ç™¾åº¦æ–°é—»..." if st.session_state.language == "zh" else "ğŸ” Step 5: Searching Baidu News with SerpApi...")
                        
                        # ä½¿ç”¨ç¿»è¯‘åçš„ä¸­æ–‡å…³é”®è¯è¿›è¡Œæœç´¢
                        news_results = search_baidu_news(translated_keywords, [], "custom", filter_start_date, filter_end_date)
                        
                        if news_results:
                            # ç¬¬å…­æ­¥ï¼šä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º
                            st.info("ğŸ¤– ç¬¬å…­æ­¥ï¼šæ­£åœ¨ä½¿ç”¨OpenAIè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º..." if st.session_state.language == "zh" else "ğŸ¤– Step 6: Formatting output with OpenAI...")
                            final_result = analyze_news_with_openai(news_results, translated_keywords, [], filter_start_date, filter_end_date)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{final_result}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_custom_result = final_result
                            st.session_state.last_custom_prompt = custom_prompt
                            st.session_state.last_extraction_result = extraction_result
                            st.session_state.last_translated_keywords = translated_keywords
                            st.session_state.last_time_range = {
                                "start_date": filter_start_date,
                                "end_date": filter_end_date,
                                "description": time_desc
                            }
                        else:
                            # å¦‚æœæœªæ‰¾åˆ°æ–°é—»
                            error_msg = "âŒ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶æˆ–æ—¶é—´èŒƒå›´ã€‚" if st.session_state.language == "zh" else "âŒ No relevant news found, please try adjusting search conditions or time range."
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                            
                            # ä¿å­˜ç»“æœåˆ°session state
                            st.session_state.last_custom_result = error_msg
                            st.session_state.last_custom_prompt = custom_prompt
                            st.session_state.last_extraction_result = extraction_result
                            st.session_state.last_translated_keywords = translated_keywords
                            st.session_state.last_time_range = {
                                "start_date": filter_start_date,
                                "end_date": filter_end_date,
                                "description": time_desc
                            }
                            
                    except Exception as e:
                        # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                        st.warning("âš ï¸ ChatGPTæå–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•..." if st.session_state.language == "zh" else "âš ï¸ ChatGPT extraction failed, using traditional method...")
                        
                        # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æå–å…³é”®è¯
                        extracted_keywords, extracted_companies = extract_search_terms_from_prompt(custom_prompt)
                        
                        # æ˜¾ç¤ºæå–çš„å…³é”®è¯
                        st.markdown("**ğŸ”‘ æå–çš„å…³é”®è¯ / Extracted Keywords:**")
                        keywords_display = ", ".join(extracted_keywords) if extracted_keywords else ("æ— " if st.session_state.language == "zh" else "None")
                        st.markdown(f'<div style="background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 5px 0;">{keywords_display}</div>', unsafe_allow_html=True)
                        
                        # ä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´
                        current_date = datetime.now()
                        filter_start_date = current_date - timedelta(days=180)  # çº¦6ä¸ªæœˆ
                        filter_end_date = current_date
                        
                        st.markdown("**â° æ—¶é—´èŒƒå›´ / Time Range:**")
                        st.markdown(f'<div style="background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 5px 0;">æœ€è¿‘6ä¸ªæœˆ / Last 6 months</div>', unsafe_allow_html=True)
                        
                        try:
                            news_results = search_baidu_news(extracted_keywords, extracted_companies, "custom", filter_start_date, filter_end_date)
                            
                            if news_results:
                                final_result = analyze_news_with_openai(news_results, extracted_keywords, extracted_companies, filter_start_date, filter_end_date)
                                
                                # æ˜¾ç¤ºåˆ†æç»“æœ
                                st.subheader(lang["analysis_results"])
                                st.markdown(f'<div style="font-size: 18px;">{final_result}</div>', unsafe_allow_html=True)
                                
                                # ä¿å­˜ç»“æœåˆ°session state
                                st.session_state.last_custom_result = final_result
                                st.session_state.last_custom_prompt = custom_prompt
                            else:
                                error_msg = "âŒ æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶æˆ–æ—¶é—´èŒƒå›´ã€‚" if st.session_state.language == "zh" else "âŒ No relevant news found, please try adjusting search conditions or time range."
                                st.subheader(lang["analysis_results"])
                                st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                                
                                st.session_state.last_custom_result = error_msg
                                st.session_state.last_custom_prompt = custom_prompt
                                
                        except Exception as e2:
                            # å¦‚æœæœç´¢å¤±è´¥
                            error_msg = f"âŒ æœç´¢å¤±è´¥: {str(e2)}"
                            st.subheader(lang["analysis_results"])
                            st.markdown(f'<div style="font-size: 18px;">{error_msg}</div>', unsafe_allow_html=True)
                            
                            st.session_state.last_custom_result = error_msg
                            st.session_state.last_custom_prompt = custom_prompt
        
        # æ˜¾ç¤ºä¸Šæ¬¡åˆ†æç»“æœ
        if 'last_custom_result' in st.session_state:
            st.markdown("---")
            st.subheader(lang["last_results"])
            
            # æ˜¾ç¤ºä¸Šæ¬¡æœç´¢çš„å‚æ•°ä¿¡æ¯
            if 'last_extraction_result' in st.session_state and 'last_time_range' in st.session_state:
                st.markdown("**ğŸ“Š ä¸Šæ¬¡æœç´¢å‚æ•° / Last Search Parameters:**")
                
                col_last1, col_last2, col_last3, col_last4 = st.columns(4)
                
                with col_last1:
                    st.markdown("**ğŸ”‘ åŸå§‹å…³é”®è¯ / Original Keywords:**")
                    last_original_keywords = ", ".join(st.session_state.last_extraction_result["keywords"]) if st.session_state.last_extraction_result["keywords"] else ("æ— " if st.session_state.language == "zh" else "None")
                    st.markdown(f'<div style="background-color: #e8f4fd; padding: 8px; border-radius: 5px; font-size: 14px;">{last_original_keywords}</div>', unsafe_allow_html=True)
                
                with col_last2:
                    st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡å…³é”®è¯ / Chinese Keywords:**")
                    last_translated_keywords = ", ".join(st.session_state.last_translated_keywords) if 'last_translated_keywords' in st.session_state and st.session_state.last_translated_keywords else ("æ— " if st.session_state.language == "zh" else "None")
                    st.markdown(f'<div style="background-color: #e8f5e8; padding: 8px; border-radius: 5px; font-size: 14px;">{last_translated_keywords}</div>', unsafe_allow_html=True)
                
                with col_last3:
                    st.markdown("**â° æ—¶é—´èŒƒå›´ / Time Range:**")
                    last_time_desc = st.session_state.last_time_range["description"]
                    st.markdown(f'<div style="background-color: #e8f4fd; padding: 8px; border-radius: 5px; font-size: 14px;">{last_time_desc}</div>', unsafe_allow_html=True)
                
                with col_last4:
                    st.markdown("**ğŸ“… å…·ä½“æ—¥æœŸ / Specific Dates:**")
                    last_start = st.session_state.last_time_range["start_date"].strftime('%Y-%m-%d')
                    last_end = st.session_state.last_time_range["end_date"].strftime('%Y-%m-%d')
                    st.markdown(f'<div style="background-color: #e8f4fd; padding: 8px; border-radius: 5px; font-size: 14px;">{last_start} ~ {last_end}</div>', unsafe_allow_html=True)
            
            with st.expander(lang["view_last_results"], expanded=False):
                st.markdown(f'<div style="font-size: 18px;">{st.session_state.last_custom_result}</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºè¯­è¨€è½¬æ¢Promptï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'last_custom_language_prompt' in st.session_state:
                    with st.expander(lang["language_conversion_prompt"], expanded=False):
                        st.markdown(f'<div style="font-size: 16px;">{st.session_state.last_custom_language_prompt}</div>', unsafe_allow_html=True)
    
    with tab3:
        st.header("ğŸ“š Search History" if st.session_state.language == "en" else "ğŸ“š æœç´¢å†å²")
        
        if st.session_state.search_history:
            if 'selected_history_item' in st.session_state and st.session_state.selected_history_item:
                # æ˜¾ç¤ºé€‰ä¸­çš„å†å²è®°å½•è¯¦æƒ…
                history_item = st.session_state.selected_history_item
                
                # åŸºæœ¬ä¿¡æ¯
                st.subheader("ğŸ“‹ Historical Search Result Details" if st.session_state.language == "en" else "ğŸ“‹ Historical Search Result Details")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**{'æœç´¢æ—¶é—´' if st.session_state.language == 'zh' else 'Search Time'}:** {history_item['date']}")
                    st.markdown(f"**{'å…³é”®è¯' if st.session_state.language == 'zh' else 'Keywords'}:** {', '.join(history_item['keywords']) if history_item['keywords'] else ('æ— ' if st.session_state.language == 'zh' else 'None')}")
                with col2:
                    st.markdown(f"**{'å…¬å¸' if st.session_state.language == 'zh' else 'Companies'}:** {', '.join(history_item['companies']) if history_item['companies'] else ('æ— ' if st.session_state.language == 'zh' else 'None')}")
                    st.markdown(f"**{'æ—¶é—´èŒƒå›´' if st.session_state.language == 'zh' else 'Time Range'}:** {history_item['time_option']}")
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("---")
                st.subheader("ğŸ” æœç´¢ç»“æœ" if st.session_state.language == "zh" else "ğŸ” Search Results")
                st.markdown(f'<div style="font-size: 18px;">{history_item["result"]}</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºPrompt
                with st.expander("ğŸ“ ç”Ÿæˆçš„Prompt" if st.session_state.language == "zh" else "ğŸ“ Generated Prompt", expanded=False):
                    st.markdown(f'<div style="font-size: 16px;">{history_item["prompt"]}</div>', unsafe_allow_html=True)
            else:
                st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©ä¸€æ¡å†å²è®°å½•ä»¥æŸ¥çœ‹è¯¦æƒ…" if st.session_state.language == "zh" else "Please select a history record in the sidebar to view details")
        else:
            st.info("æš‚æ— æœç´¢å†å²" if st.session_state.language == "zh" else "No search history yet")

if __name__ == "__main__":
    main()
